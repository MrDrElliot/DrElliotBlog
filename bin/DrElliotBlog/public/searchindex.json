[{"content":"Honestly, this has been covered in so many places, and I\u0026rsquo;m by no means a psychology professor. I have done my fair share of studying different learning and teaching techniques from when I was a flight instructor, though, so I\u0026rsquo;d like to share some thoughts on asking effective questions, especially in programming communities.\nThe Quick Reference Guide If you don\u0026rsquo;t feel like reading my post, here are some excellent resources:\nDon\u0026rsquo;t Ask to Ask No Hello How do I ask a good question? The XY Problem The Human Element Here\u0026rsquo;s the thing: programming communities are filled with people who take advantage of anonymity and forget they\u0026rsquo;re talking to another human being. Especially when asking questions.\nHave some respect. The person answering your question is donating their time and expertise. They\u0026rsquo;re not your debugging service, your personal tutor, or your employee. They\u0026rsquo;re a fellow developer who genuinely wants to help—but only if you make it worth their time.\nThe Golden Rule of Question Phrasing Give as much effort in asking your question as you would expect the person to give in answering it.\nDon\u0026rsquo;t just post a blob of code and say \u0026ldquo;why no work?\u0026rdquo; or \u0026ldquo;help plz urgent!!!\u0026rdquo; That shows you don\u0026rsquo;t value the other person\u0026rsquo;s time, and they\u0026rsquo;ll respond accordingly (or more likely, not respond at all).\nAnatomy of a Good Question 1. Context and Goal Start with what you\u0026rsquo;re trying to accomplish:\nBad:\nmy code doesn\u0026#39;t work Good:\nI\u0026#39;m trying to implement a thread-safe queue in C++ for a producer-consumer pattern, but I\u0026#39;m getting a segmentation fault when multiple threads try to pop elements. 2. What You\u0026rsquo;ve Tried Show your research and debugging efforts:\nBad:\nstd::vector\u0026lt;int\u0026gt; vec; vec[0] = 5; // crashes help??? Good:\nstd::vector\u0026lt;int\u0026gt; vec; vec[0] = 5; // Segfault here // I understand vectors start empty and need to be sized first. // I\u0026#39;ve tried: // - vec.resize(10) before accessing - this worked // - vec.reserve(10), still crashes // - vec.push_back(5), works but I need indexed access // Why does reserve() not work the same as resize()? 3. Minimal, Complete, Reproducible Example This is critical. Strip your code down to the minimum that demonstrates the problem:\nBad:\n[Dumps 500 lines of code with no context] Good:\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; class Resource { std::unique_ptr\u0026lt;int[]\u0026gt; data; public: Resource(size_t size) : data(std::make_unique\u0026lt;int[]\u0026gt;(size)) {} // Move constructor Resource(Resource\u0026amp;\u0026amp; other) noexcept : data(std::move(other.data)) {} }; int main() { Resource r1(10); Resource r2(std::move(r1)); // After moving, is r1.data guaranteed to be nullptr? // Or is it just \u0026#34;valid but unspecified\u0026#34;? return 0; } 4. Your Environment Include relevant details:\nCompiler: GCC 13.2 Flags: -std=c++20 -O2 -Wall OS: Ubuntu 22.04 Architecture: x86_64 5. Expected vs. Actual Behavior Be explicit:\nExpected: The program should print \u0026ldquo;5\u0026rdquo; to the console.\nActual: The program crashes with Segmentation fault (core dumped) at line 23.\nError messages (if any):\nerror: invalid use of incomplete type \u0026#39;class Forward\u0026#39; note: forward declaration of \u0026#39;class Forward\u0026#39; Common Mistakes to Avoid The \u0026ldquo;It Doesn\u0026rsquo;t Work\u0026rdquo; Problem Help! My code doesn\u0026#39;t work! This tells us nothing. What does \u0026ldquo;doesn\u0026rsquo;t work\u0026rdquo; mean? Does it:\nNot compile? Compile but crash? Produce wrong output? Run too slowly? Have undefined behavior? Be specific!\nThe XY Problem You\u0026rsquo;re trying to solve problem X, you think solution Y will work, so you ask about Y instead of X. Often, Y is the wrong approach entirely.\nExample:\nBad: \u0026ldquo;How do I parse HTML with regex in C++?\u0026rdquo;\nBetter: \u0026ldquo;I need to extract all \u0026lt;a\u0026gt; tag URLs from an HTML document in C++. What\u0026rsquo;s the best approach?\u0026rdquo;\nThe first question locks you into a bad solution (parsing HTML with regex). The second opens the door to better suggestions (using a proper HTML parser library).\nThe \u0026ldquo;Do My Homework\u0026rdquo; Question Write a C++ program that implements a binary search tree with insert, delete, and traversal methods. Due tomorrow. Nobody will (or should) answer this. Show what you\u0026rsquo;ve attempted, where you\u0026rsquo;re stuck, and what specific concept you\u0026rsquo;re struggling with.\nThe Zero-Effort Screenshot Don\u0026rsquo;t post screenshots of code. Don\u0026rsquo;t post photos of your screen. Copy and paste actual text that can be:\nCopy-pasted into a compiler Searched Read by screen readers The only time screenshots are acceptable is for showing UI issues or error dialogs.\nThe Debugging Checklist Before asking, make sure you\u0026rsquo;ve tried:\nReading the error message carefully - Compiler errors often tell you exactly what\u0026rsquo;s wrong Checking the documentation - RTFM is harsh but often accurate advice Searching for the error - Someone has likely encountered this before Using a debugger - Step through your code, inspect variables Adding print statements - See what\u0026rsquo;s actually happening at runtime Creating a minimal example - Often you\u0026rsquo;ll find the bug while simplifying Reading your code out loud - Rubber duck debugging works Taking a break - Fresh eyes catch obvious mistakes A Real-World Example Let me show you a question I recently encountered:\nThe Bad Version:\nunique_ptr broken help [pastes 300 lines of code] The Good Version:\nQuestion: Why does my unique_ptr lose ownership after passing to a function? Context: I\u0026#39;m implementing a custom memory pool in C++ and trying to transfer ownership of allocated blocks between objects. Code: ```cpp #include \u0026lt;memory\u0026gt; #include \u0026lt;iostream\u0026gt; void takeOwnership(std::unique_ptr\u0026lt;int\u0026gt; ptr) { std::cout \u0026lt;\u0026lt; \u0026#34;Value: \u0026#34; \u0026lt;\u0026lt; *ptr \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } int main() { auto ptr = std::make_unique\u0026lt;int\u0026gt;(42); takeOwnership(ptr); // Error: call to implicitly-deleted copy constructor return 0; } Error:\nerror: call to implicitly-deleted copy constructor of \u0026#39;std::unique_ptr\u0026lt;int\u0026gt;\u0026#39; What I\u0026rsquo;ve tried:\nUsing std::move(ptr) - this works but then ptr is empty afterward Passing by reference - works but doesn\u0026rsquo;t transfer ownership Question: Is std::move the correct approach? Should ptr be unusable after transferring ownership, or is there a better pattern for this use case?\nEnvironment: Clang 15, -std=c++20 See the difference? The second version:\nStates the actual goal Provides a minimal, compilable example Shows the exact error Demonstrates what was already tried Asks a specific question Includes environment details The Respect Factor Remember: you don\u0026rsquo;t know what you don\u0026rsquo;t know. You\u0026rsquo;re probably leaving out critical information because you don\u0026rsquo;t realize it\u0026rsquo;s critical. That\u0026rsquo;s fine, we\u0026rsquo;ve all been there.\nBut show respect by:\nDoing your homework first - Don\u0026rsquo;t ask questions easily answered by Google Valuing others\u0026rsquo; time - Make your question clear and complete Being patient - People have jobs and lives Saying thank you - Someone just saved you hours of debugging Following up - If you solve it yourself, post the solution Accepting answers - Upvote/accept solutions that help you For the Answerers If you\u0026rsquo;re on the other side and someone asks a bad question:\nDon\u0026rsquo;t be a jerk - We were all beginners once Guide them - Link to \u0026ldquo;How to ask a question\u0026rdquo; resources Ask clarifying questions - \u0026ldquo;What error do you get?\u0026rdquo; \u0026ldquo;What have you tried?\u0026rdquo; Set boundaries - It\u0026rsquo;s okay to say \u0026ldquo;Please provide a minimal example\u0026rdquo; The goal is to teach people how to think about problems, not just to fix their immediate issue.\nConclusion Asking good questions is a skill. It requires empathy, effort, and clear communication. But it\u0026rsquo;s worth developing because:\nYou\u0026rsquo;ll get better, faster answers You\u0026rsquo;ll learn to debug more effectively You\u0026rsquo;ll build better relationships in the community You\u0026rsquo;ll become a better developer And honestly? Writing a good question often leads you to the answer yourself. The process of organizing your thoughts, creating a minimal example, and explaining the problem forces you to understand it better.\nSo next time you\u0026rsquo;re about to ask a question, take five extra minutes to do it right. Those five minutes will save hours for both you and the person helping you.\nTreat others the way you\u0026rsquo;d want to be treated. And that includes their time.\nHappy debugging!\n","date":"11 October, 2025","id":0,"permalink":"/posts/general/asking/","summary":"Honestly, this has been covered in so many places, and I\u0026rsquo;m by no means a psychology professor. I have done my fair share of studying different learning and teaching techniques from when I was a flight instructor, though, so I\u0026rsquo;d like to share some thoughts on asking effective questions, especially in programming communities.","tags":"LifeLessons","title":"How to ask a question"},{"content":"Hello! Today, I want to talk about a commonly misunderstood concept in programming: Move Semantics.\nMove semantics involve efficiently transferring ownership of resources (like memory) from one object to another. This could be for a number of reasons, one example is for directly transferring ownership (which we will demonstrate) down below.\nUnderstanding L-values and R-values Before we dive into move semantics, we need to understand the fundamental distinction between l-values and r-values.\nL-values (left values) are expressions that refer to a memory location and allow us to take their address. They have a persistent identity beyond a single expression.\nint x = 10; // \u0026#39;x\u0026#39; is an l-value int* ptr = \u0026amp;x; // We can take the address of \u0026#39;x\u0026#39; x = 20; // We can assign to \u0026#39;x\u0026#39; R-values (right values) are temporary values that don\u0026rsquo;t have a persistent memory address. They\u0026rsquo;re typically the result of expressions or literals.\nint y = 5 + 3; // \u0026#39;5 + 3\u0026#39; is an r-value (temporary result) int z = x * 2; // \u0026#39;x * 2\u0026#39; is an r-value // int* ptr = \u0026amp;(x + 1); // Error! Can\u0026#39;t take address of r-value Think of it this way: l-values can appear on the left side of an assignment, r-values typically appear on the right side.\nThe Problem Move Semantics Solves Consider what happens when we return a large object from a function or pass it around:\n#include \u0026lt;vector\u0026gt; #include \u0026lt;iostream\u0026gt; class BigData { private: std::vector\u0026lt;int\u0026gt; data; public: BigData(size_t size) : data(size, 0) { std::cout \u0026lt;\u0026lt; \u0026#34;Constructor: Allocating \u0026#34; \u0026lt;\u0026lt; size \u0026lt;\u0026lt; \u0026#34; elements\\n\u0026#34;; } // Copy constructor BigData(const BigData\u0026amp; other) : data(other.data) { std::cout \u0026lt;\u0026lt; \u0026#34;Copy Constructor: Copying \u0026#34; \u0026lt;\u0026lt; data.size() \u0026lt;\u0026lt; \u0026#34; elements\\n\u0026#34;; } size_t size() const { return data.size(); } }; BigData CreateBigData() { BigData temp(1000000); // Create a big object return temp; // Without move semantics, this copies! } int main() { BigData myData = CreateBigData(); // Another copy! return 0; } Without move semantics, this code would perform expensive deep copies of the entire vector, even though temp is about to be destroyed anyway. That\u0026rsquo;s wasteful!\nEnter Move Semantics Move semantics allow us to \u0026ldquo;steal\u0026rdquo; resources from temporary objects (r-values) that are about to die anyway. Instead of copying, we simply transfer ownership.\n#include \u0026lt;vector\u0026gt; #include \u0026lt;iostream\u0026gt; class BigData { private: std::vector\u0026lt;int\u0026gt; data; public: BigData(size_t size) : data(size, 0) { std::cout \u0026lt;\u0026lt; \u0026#34;Constructor: Allocating \u0026#34; \u0026lt;\u0026lt; size \u0026lt;\u0026lt; \u0026#34; elements\\n\u0026#34;; } // Copy constructor BigData(const BigData\u0026amp; other) : data(other.data) { std::cout \u0026lt;\u0026lt; \u0026#34;Copy Constructor: Copying \u0026#34; \u0026lt;\u0026lt; data.size() \u0026lt;\u0026lt; \u0026#34; elements\\n\u0026#34;; } // Move constructor BigData(BigData\u0026amp;\u0026amp; other) noexcept : data(std::move(other.data)) { std::cout \u0026lt;\u0026lt; \u0026#34;Move Constructor: Transferring ownership\\n\u0026#34;; } // Copy assignment BigData\u0026amp; operator=(const BigData\u0026amp; other) { std::cout \u0026lt;\u0026lt; \u0026#34;Copy Assignment\\n\u0026#34;; if (this != \u0026amp;other) { data = other.data; } return *this; } // Move assignment BigData\u0026amp; operator=(BigData\u0026amp;\u0026amp; other) noexcept { std::cout \u0026lt;\u0026lt; \u0026#34;Move Assignment: Transferring ownership\\n\u0026#34;; if (this != \u0026amp;other) { data = std::move(other.data); } return *this; } size_t size() const { return data.size(); } }; BigData CreateBigData() { BigData temp(1000000); return temp; // Move constructor is called! } int main() { BigData myData = CreateBigData(); // Move, not copy! std::cout \u0026lt;\u0026lt; \u0026#34;Final size: \u0026#34; \u0026lt;\u0026lt; myData.size() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; return 0; } Output:\nConstructor: Allocating 1000000 elements Move Constructor: Transferring ownership Final size: 1000000 Notice the \u0026amp;\u0026amp; syntax? That\u0026rsquo;s an r-value reference, which allows us to bind to temporary objects and move from them.\nWhen to Use Move Semantics 1. Returning Large Objects from Functions std::vector\u0026lt;int\u0026gt; GenerateLargeVector() { std::vector\u0026lt;int\u0026gt; result(1000000, 42); return result; // Automatically moved (RVO or move constructor) } int main() { std::vector\u0026lt;int\u0026gt; myVec = GenerateLargeVector(); } 2. Transferring Ownership Explicitly #include \u0026lt;memory\u0026gt; #include \u0026lt;string\u0026gt; class Resource { private: std::unique_ptr\u0026lt;int[]\u0026gt; buffer; size_t size; public: Resource(size_t s) : buffer(std::make_unique\u0026lt;int[]\u0026gt;(s)), size(s) {} // Move constructor Resource(Resource\u0026amp;\u0026amp; other) noexcept : buffer(std::move(other.buffer)) , size(other.size) { other.size = 0; } // Move assignment Resource\u0026amp; operator=(Resource\u0026amp;\u0026amp; other) noexcept { if (this != \u0026amp;other) { buffer = std::move(other.buffer); size = other.size; other.size = 0; } return *this; } }; int main() { Resource r1(100); Resource r2 = std::move(r1); // Explicitly transfer ownership // r1 is now in a valid but unspecified state } 3. Working with Containers #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; int main() { std::vector\u0026lt;std::string\u0026gt; names; std::string temp = \u0026#34;Alice\u0026#34;; names.push_back(temp); // Copy (temp still usable) names.push_back(std::move(temp)); // Move (temp now empty) names.push_back(\u0026#34;Bob\u0026#34;); // Move (temporary string) names.emplace_back(\u0026#34;Charlie\u0026#34;); // Constructed directly in vector } 4. Implementing the Rule of Five If your class manages resources, implement all five special member functions:\nclass ResourceManager { private: int* data; size_t size; public: // Constructor ResourceManager(size_t s) : data(new int[s]) , size(s) {} // Destructor ~ResourceManager() { delete[] data; } // Copy constructor ResourceManager(const ResourceManager\u0026amp; other) : data(new int[other.size]), size(other.size) { std::copy(other.data, other.data + size, data); } // Copy assignment ResourceManager\u0026amp; operator=(const ResourceManager\u0026amp; other) { if (this != \u0026amp;other) { delete[] data; size = other.size; data = new int[size]; std::copy(other.data, other.data + size, data); } return *this; } // Move constructor ResourceManager(ResourceManager\u0026amp;\u0026amp; other) noexcept : data(other.data), size(other.size) { other.data = nullptr; other.size = 0; } // Move assignment ResourceManager\u0026amp; operator=(ResourceManager\u0026amp;\u0026amp; other) noexcept { if (this != \u0026amp;other) { delete[] data; data = other.data; size = other.size; other.data = nullptr; other.size = 0; } return *this; } }; Common Pitfalls and Best Practices Don\u0026rsquo;t Move from L-values Unless Intentional std::string name = \u0026#34;Alice\u0026#34;; std::string copy1 = name; // Copy, name still usable std::string copy2 = std::move(name); // Move, name now empty // Using \u0026#39;name\u0026#39; here is dangerous! Mark Move Operations as noexcept Move operations should be marked noexcept when possible, as this allows containers to optimize their behavior:\nBigData(BigData\u0026amp;\u0026amp; other) noexcept { // Move implementation } Use std::move Carefully std::move doesn\u0026rsquo;t actually move anything, it just casts an l-value to an r-value reference, enabling move semantics:\nstd::vector\u0026lt;int\u0026gt; v1 = {1, 2, 3}; std::vector\u0026lt;int\u0026gt; v2 = std::move(v1); // v1 is now empty Moved-from Objects are Valid but Unspecified After moving from an object, it remains in a valid state, but you shouldn\u0026rsquo;t assume what that state is. You can safely destroy it or assign to it:\nstd::string s1 = \u0026#34;Hello\u0026#34;; std::string s2 = std::move(s1); // s1 is valid but empty s1 = \u0026#34;World\u0026#34;; // OK - assigning new value Performance Benefits Move semantics can provide dramatic performance improvements:\nGodBolt -O2 -std=c++17\n#include \u0026lt;chrono\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; void TestCopy() { std::vector\u0026lt;int\u0026gt; source(10000000, 42); auto start = std::chrono::high_resolution_clock::now(); std::vector\u0026lt;int\u0026gt; dest = source; // Copy auto end = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double, std::milli\u0026gt; elapsed = end - start; std::cout \u0026lt;\u0026lt; \u0026#34;Copy took: \u0026#34; \u0026lt;\u0026lt; elapsed.count() \u0026lt;\u0026lt; \u0026#34; ms\\n\u0026#34;; } void TestMove() { std::vector\u0026lt;int\u0026gt; source(10000000, 42); auto start = std::chrono::high_resolution_clock::now(); std::vector\u0026lt;int\u0026gt; dest = std::move(source); // Move auto end = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double, std::milli\u0026gt; elapsed = end - start; std::cout \u0026lt;\u0026lt; \u0026#34;Move took: \u0026#34; \u0026lt;\u0026lt; elapsed.count() \u0026lt;\u0026lt; \u0026#34; ms\\n\u0026#34;; } int main() { TestCopy(); TestMove(); return 0; } On most systems, the move operation will be orders of magnitude faster than the copy, (dependant on optimization levels).\nConclusion Move semantics are a powerful feature in modern C++ that enable efficient resource management and transfer of ownership. By understanding l-values and r-values, implementing move constructors and move assignment operators, and using std::move judiciously, you can write more efficient and expressive C++ code.\nRemember: move semantics aren\u0026rsquo;t about doing less work, they\u0026rsquo;re about doing the right work at the right time. When an object is about to die anyway, why waste time copying its resources when we can simply take them?\nHappy coding!\n","date":"11 October, 2025","id":1,"permalink":"/posts/memory/movesemantics/","summary":"Hello! Today, I want to talk about a commonly misunderstood concept in programming: Move Semantics.","tags":"CPP C++ Optimization","title":"Move Semantics"},{"content":" Disclaimer: This post reflects general observations and lessons learned from working in creative industries.\nIt is not about any specific individual, project, or legal matter.\nStarting a project with a friend can feel like the dream, shared vision, late-night brainstorming, the excitement of building something together. But money has a strange way of distorting relationships. When financial stakes enter the picture, priorities shift, values get tested, and even the strongest friendships can fracture.\nThis is especially true in creative industries like indie game development, where people often come together for different reasons:\nOne person may want to tell a story or create art. Another may see the project as a business opportunity. Both can be valid, but the mismatch becomes dangerous when money enters the equation. The Subtle Shifts Money Brings Money has a way of magnifying small differences:\nWhat happens when one partner values artistic integrity while the other pushes for monetization? If one person feels they’re carrying more weight, resentment festers. Some are comfortable reinvesting everything; others want quick returns. What starts as “just a side project” can quickly become a battle over control, credit, or compensation.\nContracts: A Double-Edged Sword Many people assume contracts will protect them. To a degree, that’s true; clear agreements are far better than vague handshakes. But here’s the reality:\nA contract is only as strong as your willingness (and financial ability) to enforce it.\nLegal battles are expensive, slow, and emotionally draining. Even a \u0026ldquo;solid\u0026rdquo; contract can become meaningless if the cost of defending it outweighs what’s at stake.\nThis is why disputes are often settled confidentially, behind closed doors; because fighting it out rarely benefits either side in the long run.\nWhen People Have Nothing to Lose Perhaps the most dangerous shift comes when money pressure pushes someone into a corner.\nWhen a partner feels they’ve already lost control, or have little left to protect, they can become reckless, even vicious:\nAll-in aggression – They may fight not to win, but simply to hurt you or burn everything down. Abandoning principles – Values they once preached can vanish when survival or pride is at stake. Greed unchecked – Respect and collaboration dissolve, leaving only the desire to extract as much as possible before walking away. The person you thought you knew transforms. Where you once saw a friend or collaborator, you now see someone willing to risk it all, even at their own expense.\nThat shift is disorienting. Your respect for them diminishes, because their choices stop being about building something together and start being about taking, no matter the cost.\nAnd once you’ve seen that side of someone, it’s nearly impossible to unsee it.\nLessons Learned If you’re considering going into business with a friend, whether for a game, a startup, or any creative project, keep these points in mind:\nClarify motivations early. Are you both in it for art, money, or both? Write down agreements. Even if you trust each other, memory is fuzzy and perspectives shift. Plan for success AND failure. What happens if the game makes no money? What if it makes millions? Be realistic about enforcement. A contract is not a magic shield, it’s a roadmap, not a guarantee. Protect the friendship, or protect the business, but rarely both. Decide what matters more before money complicates things. Watch for “nothing-to-lose” behavior. When a partner stops caring about the outcome, things can turn ugly very quickly. Closing Thoughts Money isn’t evil, but it changes the context of relationships. What feels like collaboration can morph into negotiation, and what once felt like trust can become leverage.\nWhen you mix friendship and business, you aren’t just making a game, you’re gambling on whether your friendship can survive the weight of money, power, and ambition.\n","date":"29 September, 2025","id":2,"permalink":"/posts/general/dangersofgamedevelopment/","summary":"Starting a project with a friend can feel like the dream, shared vision, late-night brainstorming, the excitement of building something together. But money has a strange way of distorting relationships. When financial stakes enter the picture, priorities shift, values get tested, and even the strongest friendships can fracture.","tags":"LifeLessons GameDevelopment","title":"Dangers of Game Development"},{"content":"We’ve all been there:\nQ: \u0026ldquo;Hey, I’m running into an issue with X, has anyone seen this before?\u0026rdquo;\nA: \u0026ldquo;Why would you even do that? That’s wrong.\u0026rdquo;\nAnd just like that, a genuine question gets slapped down with arrogance instead of help.\nThis happens constantly in programming Discords, and other communities. The attitude usually comes from the same place: ego. For some people, programming isn’t just problem-solving, it’s a stage for flexing intelligence at the expense of others.\nIt’s toxic. It’s unnecessary. And it needs to stop.\nWhy does this happen? A few psychological and cultural factors fuel this behavior:\nThe Dunning-Kruger Effect\nBeginners who have just learned something often overestimate their grasp of it. Instead of saying, \u0026ldquo;I just figured this out too,\u0026rdquo; they posture as if they’re experts. This easily morphs into dismissive answers.\nReference: Kruger \u0026amp; Dunning (1999), “Unskilled and unaware of it” Confidence vs. Arrogance\nExplaining a concept clearly requires confidence. But when confidence turns into arrogance, answers start sounding like attacks. \u0026ldquo;That’s wrong\u0026rdquo; might feel efficient, but it’s really just lazy communication.\nPersonality \u0026amp; Status Games\nSome programmers tie their self-worth to being \u0026ldquo;the smartest in the room.\u0026rdquo; Answering with condescension becomes a way to establish dominance, not to solve the actual problem. Online anonymity and lack of accountability only magnify this.\nWhy this matters When you dismiss someone’s question with snark or superiority, here’s what you’re really doing:\nShutting down curiosity. The asker might think twice before engaging again. Weakening the community. If newcomers get burned, they stop participating. Revealing insecurity. Snide answers aren’t about knowledge; they’re about ego management. And honestly, let’s be real: you aren’t special. You aren’t inherently smarter than everyone else. No one’s impressed by how fast you can belittle someone online.\nHow to actually answer a question If you want to help without being an ass:\nAsk for context. Maybe the asker doesn’t have the same assumptions you do. Explain why something doesn’t work. Don’t just say \u0026ldquo;that’s wrong\u0026rdquo;, show why. Offer alternatives. A better answer is: \u0026ldquo;That approach won’t work because X. You might want to try Y instead.\u0026rdquo; Check your tone. Pretend you’re speaking to a coworker you don’t know well in real life. Would you phrase it the same way? Closing thought Arrogance doesn’t make you look like an expert. It makes you look insecure.\nIf someone is asking a question, it’s because they don’t know. That’s the whole point of communities, to share knowledge.\nSo next time you feel the urge to say, \u0026ldquo;Why would you even do that?\u0026rdquo;, stop. Take a breath. Answer like a human.\nBecause at the end of the day, programming isn’t about proving who’s smartest. It’s about solving problems together.\n","date":"23 September, 2025","id":3,"permalink":"/posts/general/answering/","summary":"We’ve all been there:","tags":"LifeLessons","title":"Stop Being a Condescending Asshole"},{"content":"Lumina is my ongoing game engine project written in C++. I’ve been working on it for about two years, and what started as a side experiment has turned into one of my biggest passions.\nOriginally, I was more interested in game development itself, making projects, prototypes, and ideas come to life. But over time, I found that what really grabbed me wasn’t the games — it was the engines behind them. Building the tools, systems, and architecture became far more rewarding than just shipping another game.\nSo Lumina was born.\nFrom Scratch (and Rewritten Again) Like many, I began with inspiration from TheCherno’s engine series. The first version of Lumina followed a similar structure, but eventually, I realized it wasn’t what I wanted.\nI scrapped it and rebuilt the engine from the ground up, a painful but freeing process. That rewrite gave Lumina its current direction: a cleaner, more modular design that prioritizes learning, experimentation, and modern engine features.\nKey Features C++ Reflection System\nBuilt using Libclang, enabling runtime type information, serialization, and editor integration.\nFully integrated Vulkan renderer\nThe renderer is one of the largest parts of any game engine, and I chose to invest my time in Vulkan.\nCustom Editor\nDeveloped with ImGui, providing real-time control, debugging tools, and extensibility.\nEntity-Component System (ECS)\nA dedicated focus on ECS, designed not only for performance but also for clarity. ECS is often treated like magic, Lumina’s goal is to demystify it, making it practical and approachable.\nTools \u0026amp; Extensibility\nFrom asset management to rendering abstractions, Lumina is gradually expanding into a full-fledged toolkit for engine developers and hobbyists alike.\nPhilosophy Lumina isn’t just about being another engine, it’s about learning, transparency, and accessibility. Game engine development can feel intimidating, but the project aims to make concepts like ECS, reflection, and rendering pipelines easier to understand.\nI’m building it to be:\nOpen Source — available for anyone to study, fork, and use. Freely Licensed — no paywalls or closed-off features. Collaborative — pull requests and contributions are welcome. Get Involved The project is open source and actively evolving. If you’re curious about engine internals, or if you want to contribute, check it out:\nLumina on GitHub\nBuilding games is fun, but building the tools that make them possible is where the real magic is.\n","date":"23 September, 2025","id":4,"permalink":"/lumina/lumina/","summary":"Lumina is my ongoing game engine project written in C++. I’ve been working on it for about two years, and what started as a side experiment has turned into one of my biggest passions.","tags":"GameEngine Lumina Rendering Vulkan","title":"Lumina Game Engine"},{"content":"Fun with V-Tables! Have you ever wanted to access a function, but you couldn\u0026rsquo;t because the function is private? :/ Have you wanted to replace a function in a class? Well, look no further! Today we\u0026rsquo;re going to be talking about V-Table manipulation.\nPlease note, this is purely for fun and can be dangerous to do in production environments. I don\u0026rsquo;t recommend using it for actual runtime use, but it can be an interesting exercise in how memory manipulation works and how you can use it to your advantage.\nWhat is a V-Table? A Virtual Table (or V-Table) is an essential concept in C++ for implementing polymorphism. It’s a data structure used to support dynamic dispatch for virtual functions. When you define a class with virtual functions, the compiler generates a V-Table for that class to keep track of the addresses of those virtual functions. At runtime, the V-Table is used to decide which function to call based on the type of the object, allowing polymorphism to work correctly.\nHow does it work? Here’s how a V-Table works:\nWhen a class has virtual functions, the compiler creates a special V-Table for it. Each entry in the V-Table points to a corresponding virtual function for that class. When a virtual function is called on an object, the program uses the V-Table to look up the function pointer, then calls the function based on the correct type. In other words, when you have a base class with a virtual function, the V-Table is what makes sure that the right derived class function gets called at runtime, even if the actual object type is different from the type of the reference or pointer.\nSniping the V-Table Now, here’s where the fun begins. What if you wanted to replace a function in a class at runtime? Could you do that? With a little bit of memory manipulation, you can! Let\u0026rsquo;s take a look at how we can do this in code:\nWe’ll modify the V-Table for an object and replace the address of the virtual function with one of our own choosing.\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;Windows.h\u0026gt; class SomeBase { public: virtual const char* VirtualFunction() { return \u0026#34;Hello I\u0026#39;m virtual\u0026#34;; } }; const char* CustomFunction() { return \u0026#34;Hello, I\u0026#39;ve been replaced!\u0026#34;; } int main() { SomeBase* obj = new SomeBase(); // Allocate on the heap instead of stack // Access the VTable by treating the object as a pointer to a pointer void** vtable = *(void***)obj; // Change memory protection to allow write access to the VTable DWORD oldProtect; VirtualProtect(\u0026amp;vtable[0], sizeof(void*), PAGE_EXECUTE_READWRITE, \u0026amp;oldProtect); // Replace the first entry in the VTable with our custom function vtable[0] = (void*)\u0026amp;CustomFunction; // Call the virtual function (it should now call our custom function) std::cout \u0026lt;\u0026lt; obj-\u0026gt;VirtualFunction() \u0026lt;\u0026lt; std::endl; // Expected output: \u0026#34;Hello, I\u0026#39;ve been replaced!\u0026#34; // Restore the original memory protection VirtualProtect(\u0026amp;vtable[0], sizeof(void*), oldProtect, \u0026amp;oldProtect); delete obj; // Clean up the heap-allocated object return 0; } Explanation: V-Table Access: We first access the V-Table for the object by treating the object as a pointer to a pointer (void** vtable = *(void***)obj;). Memory Protection: To modify the V-Table, we use VirtualProtect to change the memory protection of the V-Table to PAGE_EXECUTE_READWRITE, allowing us to overwrite the function pointer. Replacing the Function Pointer: We replace the first entry in the V-Table (which corresponds to the VirtualFunction) with our own custom function. Call the Function: When we call obj-\u0026gt;VirtualFunction(), it calls our custom function instead of the original virtual function. Restore Protection: Finally, we restore the original memory protection using VirtualProtect again. Why Does This Work? This works because C++ uses a V-Table to handle dynamic dispatch for virtual functions. By replacing the function pointer in the V-Table, we can redirect calls to our own function. This is a form of \u0026ldquo;sniping\u0026rdquo; the V-Table, where we modify an object\u0026rsquo;s internal function dispatch table to point to a different function.\nA Word of Caution While it’s fun to play around with V-Table manipulation, it\u0026rsquo;s important to note that doing this in real applications can lead to unpredictable behavior, crashes, or memory corruption. This technique can easily break if the compiler or platform changes the way it handles V-Tables, and the object model may vary based on compiler settings, platform, or even optimization flags.\nHere are a few things to consider:\nStability: Replacing function pointers in the V-Table can destabilize the program, especially when you\u0026rsquo;re dealing with polymorphic classes or objects with complex inheritance hierarchies. Compatibility: This code might break on different compilers or platforms, as not all compilers handle V-Tables the same way. Safety: Modifying V-Tables directly can result in undefined behavior and is generally discouraged in production code. Use this technique only for educational purposes or in very controlled environments. Conclusion V-Table manipulation is a powerful, albeit dangerous, technique that allows you to modify the behavior of classes at runtime. Whether you want to replace a function for debugging, hacking, or learning purposes, this technique offers an interesting look under the hood of C++\u0026rsquo;s polymorphism.\nThat being said, use this power wisely and remember, there’s a fine line between hacking and hacking yourself into a corner!\nHappy coding, and have fun with V-Tables!\n","date":"27 March, 2025","id":5,"permalink":"/posts/general/vtable/","summary":"A Virtual Table (or V-Table) is an essential concept in C++ for implementing polymorphism. It’s a data structure used to support dynamic dispatch for virtual functions. When you define a class with virtual functions, the compiler generates a V-Table for that class to keep track of the addresses of those virtual functions. At runtime, the V-Table is used to decide which function to call based on the type of the object, allowing polymorphism to work correctly.","tags":"Programming CPP C++","title":"Fun with V-Tables"},{"content":"Hello! Today, I want to talk about a commonly misunderstood concept in programming: Move Semantics.\nMove semantics involve efficiently transferring ownership of resources (like memory) from one object to another, instead of copying the data, which adds unnecessary overhead. This is especially important in performance-critical applications such as game development, where proper memory management can make a big difference in efficiency. Games, just like any other software, are prone to performance pitfalls caused by poor handling of move semantics. By the end of this post, you should have a better grasp of how to avoid these inefficiencies.\nWe’ll cover the basics of lvalue and rvalue, explore move semantics in C++ and Unreal Engine, and show real-world examples in both raw C++ and Unreal Engine’s C++.\nLet’s get started!\nUnderstanding the Problem Let’s first consider a raw C++ example:\nRaw C++ Code Example: #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; int gAllocations = 0; int gCopies = 0; void* operator new(size_t size) { gAllocations++; return malloc(size); } struct Data { int integer = 0; Data() = default; Data(int i) : integer(i) {} Data(const Data\u0026amp; Other) : integer(Other.integer) { gCopies++; std::cout \u0026lt;\u0026lt; \u0026#34;Copied Data\\n\u0026#34;; } }; void PrintVector(std::vector\u0026lt;Data\u0026gt; InData) { std::cout \u0026lt;\u0026lt; \u0026#34;Size: \u0026#34; \u0026lt;\u0026lt; InData.size() \u0026lt;\u0026lt; std::endl; if (InData.empty()) { return; } std::cout \u0026lt;\u0026lt; \u0026#34;Elements: { \u0026#34;; for (int i = 0; i \u0026lt; InData.size(); i++) { std::cout \u0026lt;\u0026lt; InData[i].integer; if (i \u0026lt; InData.size() - 1) { std::cout \u0026lt;\u0026lt; \u0026#34;, \u0026#34;; } } std::cout \u0026lt;\u0026lt; \u0026#34; }\\n\u0026#34;; } int main() { std::vector\u0026lt;Data\u0026gt; Numbers; for (size_t i = 0; i \u0026lt; 5; i++) { Numbers.push_back(Data(i)); } PrintVector(Numbers); std::cout \u0026lt;\u0026lt; \u0026#34;Allocation: \u0026#34; \u0026lt;\u0026lt; gAllocations \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Copies: \u0026#34; \u0026lt;\u0026lt; gCopies; std::cin.get(); } The Output: Copied Data Copied Data Copied Data ... Size: 5 Elements: { 0, 1, 2, 3, 4 } Allocation: 8 Copies: 20 Here, we have 8 allocations and 20 copies of Data. This is far from optimal and can be a performance bottleneck, especially when dealing with large datasets.\nWhy Are There So Many Copies? Passing the Vector by Value:\nThe function PrintVector takes the std::vector\u0026lt;Data\u0026gt; by value, meaning that the vector and all its elements are copied when passed. Each copy of a Data object triggers the copy constructor, which adds unnecessary overhead.\nMultiple Allocations:\nAs push_back is called, the vector resizes its internal storage, leading to multiple reallocations. Each reallocation can result in copying existing elements into new memory blocks, further adding to the overhead.\nFixing the Code with Move Semantics We can improve the performance by using move semantics. Let’s look at an optimized C++ version and then explore how Unreal Engine’s TArray can provide similar behavior.\nOptimized Raw C++ Code: #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; int gAllocations = 0; int gCopies = 0; int gMoves = 0; void* operator new(size_t size) { std::cout \u0026lt;\u0026lt; \u0026#34;Allocated: \u0026#34; \u0026lt;\u0026lt; size \u0026lt;\u0026lt; \u0026#34; bytes\\n\u0026#34;; gAllocations++; return malloc(size); } struct Data { int integer = 0; Data() = default; Data(int i) : integer(i) {} Data(const Data\u0026amp; Other) : integer(Other.integer) { gCopies++; std::cout \u0026lt;\u0026lt; \u0026#34;Copied Data\\n\u0026#34;; } Data(Data\u0026amp;\u0026amp; Other) noexcept : integer(Other.integer) { gMoves++; std::cout \u0026lt;\u0026lt; \u0026#34;Moved Data\\n\u0026#34;; Other.integer = 0; // Optional: Invalidate the source object } }; void PrintVector(const std::vector\u0026lt;Data\u0026gt;\u0026amp; InData) { std::cout \u0026lt;\u0026lt; \u0026#34;Size: \u0026#34; \u0026lt;\u0026lt; InData.size() \u0026lt;\u0026lt; std::endl; if (InData.empty()) { return; } std::cout \u0026lt;\u0026lt; \u0026#34;Elements: { \u0026#34;; for (int i = 0; i \u0026lt; InData.size(); i++) { std::cout \u0026lt;\u0026lt; InData[i].integer; if (i \u0026lt; InData.size() - 1) { std::cout \u0026lt;\u0026lt; \u0026#34;, \u0026#34;; } } std::cout \u0026lt;\u0026lt; \u0026#34; }\\n\u0026#34;; } int main() { std::vector\u0026lt;Data\u0026gt; Numbers; Numbers.reserve(5); for (size_t i = 0; i \u0026lt; 5; i++) { Numbers.emplace_back(i); } PrintVector(Numbers); std::cout \u0026lt;\u0026lt; \u0026#34;Allocations: \u0026#34; \u0026lt;\u0026lt; gAllocations \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Copies: \u0026#34; \u0026lt;\u0026lt; gCopies \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Moves: \u0026#34; \u0026lt;\u0026lt; gMoves \u0026lt;\u0026lt; std::endl; std::cin.get(); } The New Output: Allocated: 16 bytes Allocated: 20 bytes Size: 5 Elements: { 0, 1, 2, 3, 4 } Allocations: 2 Copies: 0 Moves: 0 What Changed? Passing by Const Reference:\nPassing the vector by const std::vector\u0026lt;Data\u0026gt;\u0026amp; avoids copying the entire vector and its elements when calling PrintVector.\nUsing reserve():\nPre-allocating memory with reserve(5) prevents reallocations as we insert elements, reducing the number of allocations to two.\nUsing emplace_back():\nThis avoids creating temporary objects and thus reduces unnecessary copying or moving.\nJust to put this in there, you don\u0026rsquo;t always need to use a vector if you know the size. A std::array makes more sense in situations where you know the size.\nvoid PrintVector(const std::array\u0026lt;Data, 5\u0026gt;\u0026amp; InData) { std::cout \u0026lt;\u0026lt; \u0026#34;Size: \u0026#34; \u0026lt;\u0026lt; InData.size() \u0026lt;\u0026lt; std::endl; if (InData.empty()) { return; } std::cout \u0026lt;\u0026lt; \u0026#34;Elements: { \u0026#34;; for (int i = 0; i \u0026lt; InData.size(); i++) { std::cout \u0026lt;\u0026lt; InData[i].integer; if (i \u0026lt; InData.size() - 1) { std::cout \u0026lt;\u0026lt; \u0026#34;, \u0026#34;; } } std::cout \u0026lt;\u0026lt; \u0026#34; }\\n\u0026#34;; } int main() { std::array\u0026lt;Data, 5\u0026gt; Numbers; for (size_t i = 0; i \u0026lt; 5; i++) { Numbers[i].integer = i; } PrintVector(Numbers); std::cout \u0026lt;\u0026lt; \u0026#34;Allocation: \u0026#34; \u0026lt;\u0026lt; gAllocations \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Copies: \u0026#34; \u0026lt;\u0026lt; gCopies \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Moves: \u0026#34; \u0026lt;\u0026lt; gMoves; std::cin.get(); } This my by far the most efficient.\nSize: 5 Elements: { 0, 1, 2, 3, 4 } Allocation: 0 Copies: 0 Moves: 0 But we\u0026rsquo;re more talking about vectors and dynamic memory allocation, which is why we use .reserve() to allocate the memory once where we need it.\nMove Semantics in Unreal Engine Unreal Engine’s TArray is the engine\u0026rsquo;s equivalent to std::vector in C++. Much like in raw C++, you can benefit from move semantics when working with TArray to avoid unnecessary copies and allocations.\nUnreal Engine Example: #include \u0026#34;CoreMinimal.h\u0026#34; int32 gAllocations = 0; int32 gCopies = 0; int32 gMoves = 0; void* operator new(size_t size) { gAllocations++; return FMemory::Malloc(size); } struct FData { int32 Integer = 0; FData() = default; FData(int32 i) : Integer(i) {} FData(const FData\u0026amp; Other) : Integer(Other.Integer) { gCopies++; UE_LOG(LogTemp, Warning, TEXT(\u0026#34;Copied Data\u0026#34;)); } FData(FData\u0026amp;\u0026amp; Other) noexcept : Integer(Other.Integer) { gMoves++; UE_LOG(LogTemp, Warning, TEXT(\u0026#34;Moved Data\u0026#34;)); Other.Integer = 0; // Optional: Invalidate the source object } }; void PrintTArray(const TArray\u0026lt;FData\u0026gt;\u0026amp; InData) { UE_LOG(LogTemp, Warning, TEXT(\u0026#34;Size: %d\u0026#34;), InData.Num()); if (InData.Num() == 0) { return; } FString Elements = TEXT(\u0026#34;Elements: { \u0026#34;); for (int32 i = 0; i \u0026lt; InData.Num(); i++) { Elements += FString::FromInt(InData[i].Integer); if (i \u0026lt; InData.Num() - 1) { Elements += TEXT(\u0026#34;, \u0026#34;); } } Elements += TEXT(\u0026#34; }\u0026#34;); UE_LOG(LogTemp, Warning, TEXT(\u0026#34;%s\u0026#34;), *Elements); } void TestMoveSemantics() { TArray\u0026lt;FData\u0026gt; Numbers; Numbers.Reserve(5); // Pre-allocate memory to prevent reallocations for (int32 i = 0; i \u0026lt; 5; i++) { Numbers.Emplace(i); // Emplace to avoid copies } PrintTArray(Numbers); UE_LOG(LogTemp, Warning, TEXT(\u0026#34;Allocations: %d\u0026#34;), gAllocations); UE_LOG(LogTemp, Warning, TEXT(\u0026#34;Copies: %d\u0026#34;), gCopies); UE_LOG(LogTemp, Warning, TEXT(\u0026#34;Moves: %d\u0026#34;), gMoves); } Bringing back up that std::array over std::vector point, you can use TArray allocators to solve the need to create that second allocation (Numbers.Reserve(5)). You could just inline the array allocation if you know it\u0026rsquo;s only a specific size.\nHere\u0026rsquo;s an example:\nTArray\u0026lt;FData, TInlineAllocator\u0026lt;5\u0026gt;\u0026gt; Numbers; TArray\u0026lt;FData, TFixedAllocator\u0026lt;5\u0026gt;\u0026gt; Numbers; ... The Unreal Engine Output: Copied Data Copied Data ... Size: 5 Elements: { 0, 1, 2, 3, 4 } Allocations: 2 Copies: 0 Moves: 0 Conclusion By understanding and properly applying move semantics, you can drastically reduce unnecessary allocations and copies in your programs, leading to better performance. This is especially important in performance-critical applications like game development, whether you\u0026rsquo;re using raw C++ or Unreal Engine’s TArray.\nIn our examples, both in C++ and Unreal Engine, we reduced the number of allocations and eliminated unnecessary copies by:\nPassing containers by const reference. Pre-allocating memory to prevent reallocations. Using emplace_back() in C++ or Emplace() in Unreal Engine. Mastering these techniques will help you write more efficient code in any game development environment!\nThanks for reading! Hopefully, you now have a better understanding of move semantics and how to apply them in both raw C++ and Unreal Engine.\n","date":"29 September, 2024","id":6,"permalink":"/archive/movesemantics_old/","summary":"Hello! Today, I want to talk about a commonly misunderstood concept in programming: Move Semantics.","tags":"CPP C++ Optimization","title":"Move Semantics"},{"content":"Hello! Today I wanted to talk a little bit about casting, primarily Blueprint casting. The main reason I wanted to bring this up is because it\u0026rsquo;s one of the most misunderstood and blown-out-of-proportion concepts in Unreal Engine. There\u0026rsquo;s no shortage of YouTube videos with clickbait titles like \u0026ldquo;Casting is so bad, NEVER use it in your games!\u0026rdquo; (or some variation of that). This highlights a larger problem: people creating tutorials when they have no business doing so. But I digress.\nSo what is casting? Casting is simply a way of converting one object type into another in Unreal Engine. In Blueprint, this is often done to access or interact with specific properties or methods on an object. For example, you might cast to a PlayerCharacter to access health or inventory functions from a generic object reference.\nIn C++ terms, casting is essentially telling the engine, \u0026ldquo;I know this object is actually of a more specific type, so let me treat it as that type.\u0026rdquo;\nIs casting expensive? Let’s clear this up: casting itself is not expensive. The act of casting doesn’t add significant runtime cost to your game. The real performance cost comes from asset loading, not the casting process itself. When you cast to a type, if the asset (like a skeletal mesh, material, or Blueprint class) hasn’t been loaded yet, the engine will load it. That’s where you might see a performance hit, but it happens once—after that, the asset is loaded into memory, and casting has no additional cost.\nA common misconception is the advice to \u0026ldquo;never cast on Tick.\u0026rdquo; Let me be clear: casting on Tick is fine. It doesn’t negatively affect performance in any significant way. Want to know a secret? The engine itself casts on Tick, and even Epic’s own Lyra Starter Game casts on Tick. Why? Because it doesn’t matter. If you’re worrying about saving nanoseconds, you’re over-optimizing. Don\u0026rsquo;t believe me? PROFILE.\nSo, relax—the world isn’t going to end if you cast on Tick.\nThis misunderstanding of casting has led to a lot of disinformation, causing new developers to shy away from it out of fear, or worse, use convoluted workarounds that don\u0026rsquo;t actually solve the issue.\nWhat makes casting bad? The main thing that gets casting a bad rap is the creation of hard references. A hard reference means that when one asset references another directly, Unreal has to load both assets into memory. This can create long dependency chains that cause your game or editor to stutter or hang, especially when many assets are involved.\nHowever, here\u0026rsquo;s the real kicker: it\u0026rsquo;s not the casting that causes the hard reference, it\u0026rsquo;s the pin. The \u0026ldquo;As XYZ\u0026rdquo; pin is what is causing the hard reference in your Blueprint, which is where the real problem lies. Many developers think they\u0026rsquo;re avoiding hard references by using something like an interface or event dispatcher, but if they\u0026rsquo;re still using the same reference pin, they\u0026rsquo;re still creating the hard reference. The cast node itself is not the issue; it’s the context surrounding it.\nWhat makes casting good? Now that we’ve cleared up some of the misconceptions, let’s talk about when casting is a good idea. When done right, casting is an effective tool to make your code cleaner and more efficient.\nHere are some tips to keep your casting effective:\nCast to native classes whenever possible. Native classes (C++ classes) have a lower overhead since they don\u0026rsquo;t rely on Blueprint\u0026rsquo;s reflection system, and don\u0026rsquo;t contain any other hard references (a vast majority of the time).\nIf you\u0026rsquo;re working exclusively in Blueprint, keep your base classes free of any asset references. Avoid adding things like skeletal meshes, materials, or other large assets to the base class you\u0026rsquo;re going to be casting to. This reduces the risk of inadvertently loading large assets unnecessarily.\nFor example, if you cast to a PlayerCharacter class that has a skeletal mesh component attached to it, Unreal will load the mesh as soon as the class is referenced—even if you’re just trying to access a health variable. Avoid this by keeping base classes lightweight.\nYou can also get a lot of these things without needing to cast to your player at all. For example, the On Overlap delegate that you commonly use in your Blueprints to receive a callback when your actor/component overlaps with something\u0026hellip; The Other Actor pin produces an actor reference. You can use *Get Component By Class to anonymously find a component on your actor, without needing to cast to your character, or even any character.\nThe Bigger Problem: Hard References As mentioned earlier, hard references are a larger problem than casting itself. Creating long dependency chains between assets can bring the Unreal editor (or even your game) to a screeching halt. This is especially true if you’ve got multiple assets referencing one another indirectly through these chains. Managing these references is key to keeping your game performant, and it\u0026rsquo;s something that requires thoughtful planning during development.\nBut that’s a discussion for another day.\nIn conclusion, casting has gotten a bad reputation because of misinformation. It\u0026rsquo;s not inherently bad, nor is it expensive at runtime. The real issue lies in how casting can lead to hard references, especially when combined with asset-heavy classes. By understanding how casting works, and how to minimize hard references, you\u0026rsquo;ll be in a much better position to use it efficiently in your projects.\n","date":"6 September, 2024","id":7,"permalink":"/posts/optimization/thecastscare/","summary":"Hello! Today I wanted to talk a little bit about casting, primarily Blueprint casting. The main reason I wanted to bring this up is because it\u0026rsquo;s one of the most misunderstood and blown-out-of-proportion concepts in Unreal Engine. There\u0026rsquo;s no shortage of YouTube videos with clickbait titles like \u0026ldquo;Casting is so bad, NEVER use it in your games!\u0026rdquo; (or some variation of that). This highlights a larger problem: people creating tutorials when they have no business doing so. But I digress.","tags":"UnrealEngine Paradigms Optimization","title":"The Cast Scare"},{"content":"Understanding TArray Allocators in Unreal Engine Unreal Engine\u0026rsquo;s TArray is a powerful and flexible container that allows you to manage dynamic arrays in your code. One of its lesser-known yet incredibly useful features is the ability to specify custom allocators. These allocators determine how the memory for the array is allocated and managed, which can have a significant impact on performance, especially in memory-constrained environments.\nI personally highly recommend taking a look at the VoxelCore library that\u0026rsquo;s open source on Github, they wrote lots of incredibly performant containers that are worth a lot at.\nIn this article, we\u0026rsquo;ll explore the different types of TArray allocators available in Unreal Engine, with examples demonstrating how and when to use them.\nDefault Allocator (FDefaultAllocator) Purpose: The default allocator used by TArray if no other allocator is specified. It provides a general-purpose, dynamic allocation strategy that works well in most cases.\nUse Case: Use the default allocator when you need a dynamic array that grows as needed, with no specific memory constraints.\nTArray\u0026lt;int32\u0026gt; MyArray; // Uses FDefaultAllocator by default Inline Allocator (TInlineAllocator\u0026lt;\u0026gt;) Purpose: The inline allocator allows you to specify a fixed number of elements that will be allocated inline (within the array\u0026rsquo;s memory footprint) before falling back to dynamic allocation. This can reduce heap allocations and improve performance when the array is small or has a known upper bound.\nUse Case: Use TInlineAllocator when you expect your array to be small most of the time, and you want to avoid heap allocations for those small cases.\nTArray\u0026lt;uint32, TInlineAllocator\u0026lt;4\u0026gt;\u0026gt; InlineArray; // Inlines up to 4 elements before allocating on the heap Example: Suppose you have an array that typically holds 1-4 elements, but occasionally needs to hold more. The TInlineAllocator\u0026lt;4\u0026gt; will handle the typical case without allocating heap memory, providing a performance boost.\nFixed Allocator (TFixedAllocator\u0026lt;\u0026gt;) Purpose: The fixed allocator pre-allocates a fixed block of memory for the array, meaning the array cannot grow beyond the specified size. This can be useful in performance-critical situations where you need to avoid dynamic memory allocation entirely.\nUse Case: Use TFixedAllocator when you know the maximum size of your array and need to ensure that no additional memory allocation occurs at runtime.\nTArray\u0026lt;int32, TFixedAllocator\u0026lt;16\u0026gt;\u0026gt; FixedArray; // Can hold exactly 16 elements, no more, no less Example: In a scenario where you need a small, fixed-size array (e.g., an array of 16 elements for vertex data in a shader), TFixedAllocator\u0026lt;16\u0026gt; would provide deterministic performance with no risk of runtime allocations.\nHeap Allocator (THeapAllocator\u0026lt;\u0026gt;) Purpose: The heap allocator explicitly allocates memory on the heap for the array, similar to the default allocator but more explicitly defined. This is useful when you want to ensure that the array\u0026rsquo;s memory is always allocated on the heap.\nUse Case: Use THeapAllocator when you need to guarantee that the array’s memory is allocated on the heap, regardless of its size or usage patterns.\nTArray\u0026lt;int32, THeapAllocator\u0026gt; HeapArray; // Always allocates on the heap Example: When working with large datasets or arrays that may grow significantly during runtime, THeapAllocator ensures that memory is dynamically allocated on the heap, allowing the array to expand as needed.\nSpecial Allocators (Custom Allocators) Purpose: Unreal Engine allows you to create custom allocators by inheriting from the base FMemoryAllocator class. This provides full control over how memory is allocated, aligned, and freed.\nUse Case: Use a custom allocator when you have specific memory management requirements that aren\u0026rsquo;t met by the existing allocators. This might include specialized alignment requirements or pooling strategies.\nclass FMyCustomAllocator : public FMemoryAllocator { // Custom allocator implementation here }; TArray\u0026lt;int32, FMyCustomAllocator\u0026gt; CustomArray; Example: Suppose you\u0026rsquo;re developing a real-time system with unique memory alignment or allocation requirements. A custom allocator would allow you to implement those requirements directly within the TArray.\nConclusion Choosing the right allocator for your TArray can have a significant impact on your game\u0026rsquo;s performance and memory usage. The default allocator is a good general-purpose choice, but when you need more control—whether to avoid heap allocations, limit memory usage, or meet specific performance criteria—inline, fixed, heap, or custom allocators can provide the solution.\nUnderstanding these allocators and how to use them effectively can help you write more efficient, optimized code in Unreal Engine. Whether you\u0026rsquo;re working on a small mobile game or a large AAA title, these tools give you the flexibility to manage memory in a way that best suits your project\u0026rsquo;s needs.\n","date":"16 August, 2024","id":8,"permalink":"/posts/memory/tarrayallocators/","summary":"Unreal Engine\u0026rsquo;s TArray is a powerful and flexible container that allows you to manage dynamic arrays in your code. One of its lesser-known yet incredibly useful features is the ability to specify custom allocators. These allocators determine how the memory for the array is allocated and managed, which can have a significant impact on performance, especially in memory-constrained environments.","tags":"UnrealEngine","title":"TArray Allocators"},{"content":" Unreal Engine provides various templated object pointer types that help manage memory and references to UObject instances in a safe and efficient manner. These templated types are vital for ensuring the stability and performance of your Unreal Engine projects. In this post, we\u0026rsquo;ll explore the most common templated object pointer types, explain what they do, and discuss when to use them.\n1. TObjectPtr\u0026lt;\u0026gt; Purpose: TObjectPtr is a smart pointer introduced in Unreal Engine 5, designed to replace raw pointers for referencing UObject types. It provides enhanced memory safety by automatically handling the lifetime of the referenced object. It was introduced in 5.0 and is now becoming the new norm, especially with the new incremental garbage collection being implemented in Unreal Engine 5.4.\nUse Case: Use TObjectPtr when you want to ensure safe and efficient references to UObject instances, particularly when ownership semantics are important, and to be allow for reference tracking.\nTObjectPtr\u0026lt;UTexture2D\u0026gt; MyTexture; 2. TWeakObjectPtr\u0026lt;\u0026gt; Purpose: TWeakObjectPtr is a non-owning smart pointer that references a UObject without preventing it from being garbage collected. It allows you to check if the object is still valid before accessing it.\nUse Case: Use TWeakObjectPtr when you need a reference to a UObject that might be destroyed or unloaded, and you don\u0026rsquo;t want to keep it alive unnecessarily.\nTWeakObjectPtr\u0026lt;AActor\u0026gt; WeakActorPtr; 3. TSoftObjectPtr\u0026lt;\u0026gt; Purpose: TSoftObjectPtr is a smart pointer that holds a reference to a UObject asset by its path, without loading the asset into memory until it\u0026rsquo;s explicitly needed. This is useful for optimizing memory usage.\nUse Case: Use TSoftObjectPtr for assets that are not immediately needed, such as optional or large assets, where you want to load them only when required.\nTSoftObjectPtr\u0026lt;UTexture2D\u0026gt; SoftTexture; 4. TSoftClassPtr\u0026lt;\u0026gt; Purpose: TSoftClassPtr is similar to TSoftObjectPtr, but it specifically references a class instead of an object. It holds the class by its path and loads it only when necessary.\nUse Case: Use TSoftClassPtr when you want to reference a class that may not be needed immediately, such as a blueprint class or a specific gameplay actor class.\nTSoftClassPtr\u0026lt;AActor\u0026gt; SoftActorClass; 5. TSubclassOf\u0026lt;\u0026gt; Purpose: TSubclassOf is a templated class used to store references to classes derived from a specified base class. It ensures that only valid subclasses are assigned to the variable, which is particularly useful for blueprint interactions.\nUse Case: Use TSubclassOf when you need to reference a class type, especially when dealing with blueprints or dynamically spawning actors.\nTSubclassOf\u0026lt;AActor\u0026gt; ActorSubclass; 6. TLazyObjectPtr\u0026lt;\u0026gt; Purpose: TLazyObjectPtr is designed to handle objects that might be unloaded and reloaded during gameplay. It maintains a reference to the object even if it is unloaded and can resolve it when the object is reloaded.\nUse Case: Use TLazyObjectPtr when referencing objects that might be dynamically loaded or unloaded, such as with level streaming or large datasets.\nTLazyObjectPtr\u0026lt;AActor\u0026gt; LazyActorPtr; 7. TScriptInterface\u0026lt;\u0026gt; Purpose: TScriptInterface is a templated type that holds a reference to an object that implements a specific interface. It allows interaction with the interface without knowing the underlying object type.\nUse Case: Use TScriptInterface when you need to interact with different objects through a common interface, especially useful in blueprint scripting and interface-driven design.\nTScriptInterface\u0026lt;IMyInterface\u0026gt; InterfacePtr; Conclusion Each of these templated object pointer types in Unreal Engine serves a specific purpose in managing references to UObject instances, ensuring safe memory management and optimal performance. Understanding when and how to use these types is essential for effective Unreal Engine development. By mastering these pointers, you can write more robust, efficient, and maintainable code.\n","date":"16 August, 2024","id":9,"permalink":"/posts/memory/templateobjecttypes/","summary":"Unreal Engine provides various templated object pointer types that help manage memory and references to UObject instances in a safe and efficient manner. These templated types are vital for ensuring the stability and performance of your Unreal Engine projects. In this post, we\u0026rsquo;ll explore the most common templated object pointer types, explain what they do, and discuss when to use them.","tags":"UnrealEngine","title":"Templated Object Types"},{"content":"What Are Soft References? Soft references are a way to reference an object in Unreal Engine without forcing it to stay in memory. This can be incredibly useful in scenarios where you need to reference assets like textures, sounds, or even entire levels, but don’t want to load them into memory until absolutely necessary.\nWhy Use Soft References? Imagine your game has a massive library of assets. Loading everything at once would quickly consume your memory, leading to performance issues or, worse, crashing your game. This is where soft references come in handy. They allow you to keep a \u0026ldquo;pointer\u0026rdquo; to an asset, but the asset itself is not loaded into memory until you explicitly tell it to.\nThink of soft references as an invitation to a party—you have the address (the reference), but you don’t actually show up at the party (load the asset) until you decide it’s time to go. This way, you avoid overcrowding (memory overload) and only arrive (load the asset) when it’s relevant to the gameplay.\nHow Do Soft References Work? Soft references in Unreal are often used with the TSoftObjectPtr and TSoftClassPtr templates. These templates allow you to reference an object or class without immediately loading it into memory. When you need the object, you simply resolve the reference, which loads the asset at that moment.\nFor example:\nTSoftObjectPtr\u0026lt;UTexture2D\u0026gt; SoftTexture; In the code above, SoftTexture is a soft reference to a texture. The texture isn’t loaded until you call SoftTexture.LoadSynchronous(). Until then, it’s just a reference, taking up minimal memory.\nSynchronous Loading vs Asynchronous Loading When it comes to loading assets referenced by soft references, you have two main options: synchronous loading and asynchronous loading.\nSynchronous Loading Synchronous loading means that the asset is loaded immediately, and the game waits until this process is complete before continuing. This is straightforward and ensures the asset is available right when you need it. However, it also means that the game will pause (or experience a hitch) while the asset loads, which can lead to noticeable frame drops or stuttering, especially if the asset is large or the game is running on hardware with limited resources.\nIn the earlier example:\nSoftTexture.LoadSynchronous(); This method blocks everything else until the texture is fully loaded, which is great for critical assets that must be available right away but can cause issues in scenarios where smooth gameplay is crucial.\nAsynchronous Loading Asynchronous loading, on the other hand, loads the asset in the background, allowing the game to continue running smoothly. This is particularly useful for assets that don’t need to be immediately available or for situations where you want to avoid disrupting the player’s experience.\nTo load an asset asynchronously, you typically use a function like:\nTSoftObjectPtr\u0026lt;UTexture2D\u0026gt; SoftTexture; UAssetManager::GetStreamableManager().RequestAsyncLoad(SoftTexture.ToSoftObjectPath(), FStreamableDelegate::CreateWeakLambda(this, [SoftTexture] { SoftTexture.LoadSynchronous(); /* Either .Get() or .LoadSynchronous(), the object is already loaded either way */ })); With asynchronous loading, the game doesn\u0026rsquo;t stop to wait for the asset to load, which helps maintain performance. However, this also means you need to handle the case where the asset isn’t ready when you need it. You might need to display a placeholder or delay an action until the asset is fully loaded.\nIssues with Synchronous and Asynchronous Loading Both methods come with trade-offs:\nSynchronous Loading: The primary issue is the potential for hitches or pauses in gameplay, especially when loading large assets. It’s simple but can be disruptive if not used carefully.\nAsynchronous Loading: While it helps maintain smooth gameplay, it requires additional logic to handle the period where the asset is not yet available. If not managed well, this can lead to missing assets or awkward transitions in gameplay.\nWhen Should You Use Each? The choice between synchronous and asynchronous loading depends on your game’s needs:\nUse synchronous loading for assets that are critical and need to be available immediately, but be mindful of potential hitches. Use asynchronous loading for assets that can load in the background without affecting the immediate gameplay experience, but ensure you have a plan for handling the absence of the asset during the load. When Soft References Might Not Be the Best Choice While soft references are powerful, they aren’t always the optimal solution. Here are a few scenarios where soft references might not make sense:\nFrequently Used Assets: If an asset is used frequently throughout the game, such as core UI elements, main character models, or constantly played sound effects, it might be more efficient to use a hard reference or preload the asset. The overhead of constantly resolving a soft reference might outweigh the memory savings.\nCritical Path Assets: For assets that are essential to the game’s primary gameplay loop or are needed instantly during gameplay, soft references might introduce unwanted delays. In such cases, preloading or using a hard reference ensures the asset is always ready.\nSmall Assets: For small assets that don’t consume much memory, the benefit of using soft references diminishes. It might be simpler to keep these assets loaded rather than managing their load states through soft references.\nAssets Already Loaded by Other Means: If an asset is already loaded into memory because it’s part of a larger loaded package (like a level or a character model), using a soft reference to the same asset might be redundant and unnecessary.\nStreaming Levels: When using Unreal’s level streaming system, certain assets might be better managed through the level’s streaming setup rather than through soft references. Streaming levels handle the memory management for you, so adding another layer of soft reference management might complicate things unnecessarily.\nConclusion Soft references are a powerful tool in Unreal Engine that give you greater control over memory management and asset loading. They are ideal for managing memory in large games or for assets that aren’t always needed immediately. However, they are not a one-size-fits-all solution. For assets that are frequently used, critical to gameplay, or already managed by other systems, hard references or preloading might be a better choice.\nBy understanding when and how to use soft references, and recognizing when they might not be the best fit, you can optimize your game’s performance while keeping memory usage in check. This balanced approach is key to maintaining a smooth and efficient gaming experience.\n","date":"16 August, 2024","id":10,"permalink":"/posts/memory/softreferences/","summary":"Soft references are a way to reference an object in Unreal Engine without forcing it to stay in memory. This can be incredibly useful in scenarios where you need to reference assets like textures, sounds, or even entire levels, but don’t want to load them into memory until absolutely necessary.","tags":"Optimization UnrealEngine CPP C++","title":"What Are Soft References?"},{"content":"C++ Is Not Better Than Blueprint—They’re Just Different You’ve probably heard the argument before: “C++ is better than Blueprint.” Often, this comes from people who are new to using C++ in Unreal Engine and are riding the peak of the Dunning-Kruger effect.\nThe truth is, one isn’t better than the other—they’re just different. It’s like comparing a knife to a fork; they are different tools for different jobs. Claiming that C++ is superior to Blueprint, comes across as arrogant.\nThe reality is simple: use whatever you\u0026rsquo;re comfortable with. Game development is hard—really hard. It becomes even more challenging when someone insists that Blueprint is inferior, urging you to drop everything and start following C++ tutorials. Use the tools that make you feel most at ease, and if you want to learn C++, go for it. But don’t do it because you think you’re missing out.\nUnderstanding the Differences Yes, there are reasons to choose C++ over Blueprint for specific tasks, and it’s true that Blueprint is marginally slower than C++ in terms of execution time. But that’s what the profiler is for—use it to identify and optimize performance bottlenecks, and I cannot stress this enough.\nAs a newer developer, you’re unlikely to run into the limitations of Blueprint anytime soon, especially until you start diving into more advanced multiplayer features. When you do, you’ll naturally transition to using C++ where it’s necessary.\nConclusion In the end, it’s not about which tool is better—it’s about which tool is better for you, right now. Both C++ and Blueprint have their places in Unreal Engine development. They complement each other, providing flexibility and power depending on the needs of the project. So, focus on mastering the tool that makes you most productive, and remember: there’s no one-size-fits-all in game development.\nWhen the time comes, you’ll know when to dive into C++. Until then, enjoy the journey, keep learning, and don’t let anyone else dictate the path you take.\n","date":"16 August, 2024","id":11,"permalink":"/posts/general/bpvscpp/","summary":"You’ve probably heard the argument before: “C++ is better than Blueprint.” Often, this comes from people who are new to using C++ in Unreal Engine and are riding the peak of the Dunning-Kruger effect.","tags":"UnrealEngine Blueprint","title":"Blueprint vs C++"},{"content":"Simple way to possibly increase some performance. This blog is a follow-up to this YouTube video: https://www.youtube.com/watch?v=8-VZoXn8f9U\nConsider the following code:\n// ConstexprExample.cpp : This file contains the \u0026#39;main\u0026#39; function. Program execution begins and ends there. // #include \u0026lt;iostream\u0026gt; #include \u0026lt;chrono\u0026gt; int Fibonacci(int n) { if (n \u0026lt;= 1) return n; return Fibonacci(n - 1) + Fibonacci(n - 2); } constexpr int Fibonacci_C(int n) { if (n \u0026lt;= 1) return n; return Fibonacci_C(n - 1) + Fibonacci_C(n - 2); } int main() { auto Start = std::chrono::high_resolution_clock::now(); constexpr int num = 25; constexpr int result_c = Fibonacci_C(num); std::cout \u0026lt;\u0026lt; \u0026#34;Constexpr Fibonacci: \u0026#34; \u0026lt;\u0026lt; result_c \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; std::cout \u0026lt;\u0026lt; \u0026#34;Time Taken: \u0026#34; \u0026lt;\u0026lt; std::chrono::duration_cast\u0026lt;std::chrono::microseconds\u0026gt;(std::chrono::high_resolution_clock::now() - Start).count() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; Start = std::chrono::high_resolution_clock::now(); int result = Fibonacci(num); std::cout \u0026lt;\u0026lt; \u0026#34;Normal Fibonacci: \u0026#34; \u0026lt;\u0026lt; result \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; std::cout \u0026lt;\u0026lt; \u0026#34;Time Taken: \u0026#34; \u0026lt;\u0026lt; std::chrono::duration_cast\u0026lt;std::chrono::microseconds\u0026gt;(std::chrono::high_resolution_clock::now() - Start).count(); } Performance Differences Here we see we are evaluating a classic Fibonacci recursive function. Recursion like this can be incredibly expensive. On the order of O(2^n).\nWhen comparing the two versions of the Fibonacci function—one using a normal recursive function (Fibonacci) and the other using constexpr (Fibonacci_C)—we can observe significant performance differences, especially as the input size increases.\nFibonacci (Normal Function) The Fibonacci function is evaluated at runtime. Every time the program is executed, the function goes through the recursive calls to compute the result, which can be quite costly. For example, with n = 25, the function performs thousands of recursive calls, resulting in significant computational overhead. As the input grows, the execution time increases exponentially, which is evident from the output when you measure the time taken for the function to compute the result.\nFibonacci_C (Constexpr Function) On the other hand, the Fibonacci_C function is a constexpr function. If the input is known at compile time (as in this case, with num = 25), the compiler can evaluate the function during compilation. This means the result is computed once, and the precomputed value is embedded directly into the binary, leading to a drastic reduction in runtime computation. The time measured in this scenario is almost negligible because the function itself isn\u0026rsquo;t actually being executed at runtime—the value is already there.\nOutput Comparison The difference in time taken for the two approaches might look something like this:\nConstexpr Fibonacci: 75025 Time Taken: 211 microseconds Normal Fibonacci: 75025 Time Taken: 620 microseconds These numbers will grow exponentially the larger the input number (number of recursive functions) is.\nIn this hypothetical output, we see that the constexpr version takes effectively no time at runtime because the work was done at compile time, whereas the normal function takes a considerable amount of time due to the nature of recursion.\nconstexpr vs. consteval constexpr Definition: constexpr is a keyword introduced in C++11 that suggests to the compiler that the function can be evaluated at compile time. However, if the inputs are not known at compile time, the function will be executed at runtime. Usage: Use constexpr when you want a function to be evaluated at compile time if possible, but you\u0026rsquo;re okay with it being evaluated at runtime if necessary. Pros: Flexibility: It allows both compile-time and runtime evaluation. Performance: If evaluated at compile time, it can reduce runtime overhead. Cons: Uncertainty: There’s no guarantee that the function will always be evaluated at compile time, depending on the context in which it is used. consteval Definition: consteval, introduced in C++20, forces a function to be evaluated at compile time. If you try to call a consteval function with inputs that are not known at compile time, the code will not compile. Usage: Use consteval when you want to ensure that a function is always evaluated at compile time, without exception. Pros: Guarantees: You can be certain that the function is never evaluated at runtime, which can be crucial for certain performance-critical or safety-critical applications. Cons: Rigidity: You lose the flexibility of runtime evaluation. If the inputs aren\u0026rsquo;t known at compile time, you can\u0026rsquo;t use a consteval function. When to Use constexpr vs. consteval When to Use constexpr: When you have functions that could benefit from compile-time evaluation but may also need to support runtime evaluation depending on the context. For code that is part of a library where flexibility is important—allowing the user to decide if they want compile-time or runtime evaluation. When to Use consteval: When you require the result to be known at compile time, such as in the case of template metaprogramming or when defining constants that must be computed at compile time. For performance-critical code where runtime computation would be prohibitively expensive, and you want to guarantee compile-time computation. Conclusion Understanding the differences between constexpr and consteval can significantly influence the performance of your code. constexpr offers flexibility but leaves the decision to the compiler, while consteval provides certainty at the cost of flexibility. Depending on the specific needs of your application—whether you prioritize performance, compile-time guarantees, or runtime flexibility—choosing the right tool for the job can lead to more efficient and maintainable code.\nAs always, profile your code and consider the specific context in which you\u0026rsquo;re working to make the best decision.\n","date":"16 August, 2024","id":12,"permalink":"/posts/general/constexpr/","summary":"This blog is a follow-up to this YouTube video: https://www.youtube.com/watch?v=8-VZoXn8f9U","tags":"C++ CPP Optimization","title":"Constexpr and Consteval"},{"content":"Inheritance in object-oriented programming (OOP) is a fundamental concept that is deeply embedded in the design of Unreal Engine, and in many cases, it\u0026rsquo;s an elegant and powerful tool. However, like any tool, it can be overused, leading developers into a trap that can complicate development and maintenance in the long run.\nThe Trap of Overusing Inheritance Inheritance is often the go-to solution for sharing functionality across different classes. While it provides a straightforward way to extend and modify behavior, over-relying on it can lead to a rigid and tightly coupled codebase. This rigidity can make your codebase inflexible, harder to maintain, and challenging to extend. When you heavily depend on inheritance, you might find yourself in a situation where changing a base class can have far-reaching and unintended consequences across your entire project.\nThe Modular Approach: A Look at the Gameplay Ability System A prime example of avoiding the pitfalls of overusing inheritance is Unreal Engine\u0026rsquo;s Gameplay Ability System (GAS). GAS is designed to manage complex character abilities in a modular and decoupled way, which contrasts sharply with inheritance-heavy designs. In GAS, each ability is a self-contained unit that operates independently, without direct references to other abilities or game systems.\nPeople always try do that, the first thing they try is- \u0026ldquo;Where is the handle of the ability?\u0026rdquo;, and \u0026ldquo;How I know the reference of the ability?\u0026rdquo;. -Middle\nWhen developers first approach GAS, they often ask, \u0026ldquo;Where is the handle of the ability?\u0026rdquo; or \u0026ldquo;How do I know the reference of the ability?\u0026rdquo; This mindset reflects a more traditional, inheritance-based approach. However, GAS encourages a modular design where abilities are encapsulated and interacted with through predefined interfaces and events, not direct modifications. This decoupled approach is similar to fragment design, emphasizing composition over inheritance and ensuring that each part of the system can evolve independently without breaking other parts.\nAlternatives to Inheritance To avoid the pitfalls of overusing inheritance, it\u0026rsquo;s essential to explore and utilize other design paradigms. One such approach is fragment design, which I personally favor. This style emphasizes breaking down functionality into smaller, reusable components that can be composed together in flexible ways.\nFragment design allows you to create a more modular and decoupled system. In Unreal Engine, this can be achieved through the use of Instanced UObjects and FInstancedStructs. These can encapsulate specific pieces of functionality, which can then be attached to different actors or used across different systems without the need for a shared base class. This approach minimizes dependencies between classes and encourages composition over inheritance.\nFor larger systems, UActorComponents are another powerful tool in Unreal Engine. They can be individually placed on actors, each providing a specific piece of functionality. By utilizing components, you can avoid the pitfalls of deep inheritance hierarchies, creating actors that are flexible and easily extended without being tied to a common base class.\nThe Problem with Data Handles/Injection While fragment design offers a compelling alternative to inheritance, another approach that has gained popularity is the use of data handles or dependency injection. However, I believe that this approach can be even more problematic than inheritance. Data injection often leads to hidden dependencies and can make it difficult to trace how data flows through your system. This can create a codebase that is hard to debug and maintain, as the relationships between objects become obscured.\nThe Role of Interfaces Interfaces are another tool often used to reduce the reliance on inheritance by defining a contract that multiple classes can implement. However, they are not a silver bullet. Overuse of interfaces can lead to its own set of problems, particularly in Unreal Engine. Interfaces can make your code harder to understand, as you might end up with a proliferation of small, single-purpose interfaces that can complicate your class design.\nWhile interfaces have their place, they should be used judiciously. Instead of relying heavily on interfaces, I recommend focusing on a fragment-style design that encourages composition over inheritance and interface implementation.\nThe Long-Term Benefits By limiting the use of inheritance and embracing modular, component-based designs, you can create a codebase that is more adaptable and easier to maintain. In the long run, this approach will save you time and effort as your project grows in scope and complexity. Unreal Engine provides a wealth of tools and patterns that support this style of development, from instanced objects and structs to actor components and interfaces.\nIn summary, while inheritance is a powerful feature of OOP and Unreal Engine, it\u0026rsquo;s essential to be mindful of its limitations. By exploring other programming styles, such as fragment design and component-based architecture, you can build a more flexible and maintainable framework for your games. Avoid the trap of deep inheritance hierarchies and instead strive for a modular approach that will serve you well throughout the lifecycle of your projects.\n","date":"16 August, 2024","id":13,"permalink":"/posts/general/inheritenceoveruse/","summary":"Inheritance in object-oriented programming (OOP) is a fundamental concept that is deeply embedded in the design of Unreal Engine, and in many cases, it\u0026rsquo;s an elegant and powerful tool. However, like any tool, it can be overused, leading developers into a trap that can complicate development and maintenance in the long run.","tags":"LifeLessons Paradigms","title":"Overuse of Inheritence."},{"content":"Using Lambdas in Unreal can be dangerous! Lambdas, or anonymous functions, in Unreal Engine can be very useful for writing concise and flexible code. However, they come with certain dangers, particularly when dealing with the lifetime of objects and capturing variables by reference. Here’s why:\n1. Capturing by Reference and Object Lifetimes When you use lambdas in Unreal Engine, you might capture variables by reference, which is common for avoiding unnecessary copying. However, if the lambda is executed asynchronously (e.g., in a timer, or a delegate callback), the objects referenced might be destroyed or go out of scope by the time the lambda is executed. This leads to dereferencing invalid memory, causing crashes with errors like:\nUnhandled Exception: EXCEPTION_ACCESS_VIOLATION reading address 0x0000000000000000 This particular error occurs because the lambda is trying to access an object or memory location that no longer exists, often leading to a null pointer dereference.\n2. Deferred Execution In Unreal, many systems use deferred execution, where code is scheduled to run later (e.g., after a delay, or on the next frame). Lambdas are often used in these scenarios for their flexibility. However, if the lambda captures pointers or references to Unreal objects that may be garbage collected or destroyed before the lambda runs, the lambda will end up accessing invalid memory. This is especially problematic in cases where the object’s destruction isn’t under your control, such as when the object is managed by Unreal’s garbage collector.\n3. Complex Debugging Lambdas can obscure the flow of your code, making debugging more complex. When a crash happens inside a lambda, the stack trace might not clearly indicate where or why it occurred. This is because the lambda could be executed in a completely different context from where it was defined, making it difficult to track down the source of the problem.\n4. Capturing this Another common pitfall is capturing this inside a lambda. If the lambda is executed after the object has been destroyed, it will try to access a member function or variable of an object that no longer exists, leading to undefined behavior. This is particularly dangerous in Unreal, where object lifetimes are managed in complex ways, especially with asynchronous tasks.\nHow to Mitigate These Issues Prefer Capturing by Value: If possible, capture variables by value rather than by reference. This way, the lambda will have its own copy of the data, independent of the original object\u0026rsquo;s lifetime.\nUse TWeakObjectPtr: When capturing pointers to Unreal objects, consider using TWeakObjectPtr instead of raw pointers. TWeakObjectPtr will safely handle cases where the object is destroyed, allowing you to check if the object is still valid before accessing it.\nCheck for Validity: Before accessing any captured pointers or references, explicitly check their validity within the lambda. This includes checking if pointers are nullptr or if TWeakObjectPtr is still valid.\nKeep Lambdas Small and Focused: Try to keep lambdas small and focused on a single task. This makes it easier to track down issues and reduces the likelihood of capturing unnecessary variables.\nUsing a Weak Lambda. Some may consider this a hack, but a weak lambda allows you to safely reference an object inside of a lambda, and avoid calling the lambda through the delegate if the owning object is invalid. \u0026ndash; Here is a quick example of a weak lambda in use. Taken from TestBTTask_TimerBasedLatent.cpp\nif (const UWorld* World = OwnerComp.GetWorld()) { const float DeltaTime = NumTicksExecuting * FAITestHelpers::TickInterval; World-\u0026gt;GetTimerManager().SetTimer(TaskMemory-\u0026gt;TimerHandle, FTimerDelegate::CreateWeakLambda(this, [\u0026amp;OwnerComp, TaskMemory, this]() // \u0026lt;---- This is the declaration of a weak lambda { TaskMemory-\u0026gt;TimerHandle.Invalidate(); ensure(!TaskMemory-\u0026gt;bIsAborting); LogExecution(OwnerComp, LogIndexExecuteFinish); FinishLatentTask(OwnerComp, LogResult); }), DeltaTime, false); } By being aware of these potential dangers and taking appropriate precautions, you can safely use lambdas in Unreal Engine without running into unexpected crashes or undefined behavior.\n","date":"16 August, 2024","id":14,"permalink":"/posts/general/lambdadangers/","summary":"Lambdas, or anonymous functions, in Unreal Engine can be very useful for writing concise and flexible code. However, they come with certain dangers, particularly when dealing with the lifetime of objects and capturing variables by reference. Here’s why:","tags":"Programming","title":"The dangers of Lambdas"},{"content":"","date":"16 August, 2024","id":15,"permalink":"/posts/gas/intro/","summary":"","tags":"UnrealEngine GAS","title":"Intro to GAS"},{"content":"Buffers are simply containers of bytes that can store raw data using memory offsets. Understanding how to effectively manage these buffers is essential for tasks like serialization, deserialization, and data storage.\nRaw C++ Buffer Management In raw C++, managing buffers and packing data requires manual handling of memory offsets. For example, consider the following code that packs several uint32_t values into a std::vector\u0026lt;std::byte\u0026gt; buffer:\n#include \u0026lt;vector\u0026gt; #include \u0026lt;cstdint\u0026gt; #include \u0026lt;cstring\u0026gt; // For std::memcpy void PackData() { // Buffer to hold the packed data std::vector\u0026lt;std::byte\u0026gt; buffer; // Example data std::vector\u0026lt;uint32_t\u0026gt; data = { 1234, 5678, 91011 }; // Calculate the total size needed for the buffer size_t totalSize = data.size() * sizeof(uint32_t); // Resize the buffer to fit the data buffer.resize(totalSize); // Copy each uint32_t into the buffer for (size_t i = 0; i \u0026lt; data.size(); ++i) { // Calculate the offset in the buffer size_t offset = i * sizeof(uint32_t); // Use std::memcpy to copy the data std::memcpy(buffer.data() + offset, \u0026amp;data[i], sizeof(uint32_t)); } } In this example, the buffer is resized to hold the data, and each uint32_t value is copied into the buffer at the appropriate offset.\nSimplified Buffer Management in Unreal Engine Unreal Engine simplifies this process with its FMemoryReader and FMemoryWriter classes. These classes handle the serialization and deserialization of data, abstracting away manual memory management.\nUsing FMemoryWriter To write data to a buffer, use FMemoryWriter:\n#include \u0026#34;Serialization/MemoryWriter.h\u0026#34; #include \u0026#34;Containers/Array.h\u0026#34; void SerializeData() { int32 SomeInt = 32; TArray\u0026lt;uint8\u0026gt; Buffer; { // Create a memory writer to serialize data FMemoryWriter Writer(Buffer, true /*bSerializeAsSingleBlock*/); Writer \u0026lt;\u0026lt; SomeInt; } } Using FMemoryReader To read data from a buffer, use FMemoryReader:\n#include \u0026#34;Serialization/MemoryReader.h\u0026#34; #include \u0026#34;Containers/Array.h\u0026#34; void DeserializeData() { int32 DeserializedInt = 0; TArray\u0026lt;uint8\u0026gt; Buffer; // Assume this buffer has been filled with data { // Create a memory reader to deserialize data FMemoryReader Reader(Buffer, true /*bDeserializeAsSingleBlock*/); Reader \u0026lt;\u0026lt; DeserializedInt; } } Explanation FMemoryWriter: Writes data to a TArray\u0026lt;uint8\u0026gt; buffer. The bSerializeAsSingleBlock flag optimizes memory usage by serializing the data in one contiguous block. FMemoryReader: Reads data from a TArray\u0026lt;uint8\u0026gt; buffer. The bDeserializeAsSingleBlock flag optimizes memory access during deserialization. These classes simplify the process of packing and unpacking data, allowing you to focus on higher-level functionality without worrying about manual offset calculations.\nConclusion Whether you\u0026rsquo;re working with raw C++ or leveraging Unreal Engine\u0026rsquo;s built-in classes, managing buffers and memory efficiently is crucial for effective data handling. Unreal Engine\u0026rsquo;s FMemoryReader and FMemoryWriter provide powerful abstractions that streamline these processes, making your development workflow smoother and more robust.\n","date":"16 August, 2024","id":16,"permalink":"/posts/memory/buffers/","summary":"Buffers are simply containers of bytes that can store raw data using memory offsets. Understanding how to effectively manage these buffers is essential for tasks like serialization, deserialization, and data storage.","tags":"C++ UnrealEngine CPP","title":"Working With Buffers"},{"content":"About Me Hello, and welcome to my blog!\nI’m a self-taught programmer with a deep curiosity for how things work under the hood. Most of my time these days is spent on Lumina, my custom C++ game engine, a long-term project combining my love for systems programming, graphics, and engine architecture.\nBy day, I’m an airline pilot, though I prefer to keep that part of my life private. If you’d like to reach out or ask questions about programming or game development, feel free to connect on Discord.\nI’ve also worked on (or am currently part of) several projects built with Unreal Engine, some of which you can find on Steam (in order of release):\nThe Other Side – no longer involved or supported Just War Trains – may revive one day Dead Signal – contract work Egg Game – an ancient piece of art Unreleased / In Development:\nOddstone – TBD Unlucky Few – Zombie survival Here, I post insights about Unreal Engine, programming in general, and occasionally share life lessons, reflections, and thoughts from my journey as a developer and hobbyist.\nI previously owned and operated a game development studio, but due to disagreements, the studio is now closed. A confidential settlement agreement was reached by all parties involved.\nBeyond Development Outside of programming, I’m a lifelong gamer, inspired by classics like Fallout 3 and Fallout: New Vegas. I’m also a huge fan of John Carpenter’s The Thing (1982), which I consider one of the finest horror films ever made.\nI enjoy exploring storytelling, atmosphere, and design — whether in games, movies, or personal projects — and I often find inspiration in these experiences for my own work.\nWhy This Blog? This blog is my place to share insights, techniques, and lessons learned, both the successes and the mistakes. Game engine development is an ongoing journey, and I hope that by documenting it, I can help others navigate similar paths while keeping a record of my own growth.\nExpect posts ranging from engine design deep dives and programming tips to personal reflections and the occasional story from my development adventures.\nDisclaimer As with anything you read online, don’t take my word as gospel. Always test for yourself, verify results, and approach every piece of advice with curiosity and a critical mindset.\nSpecial Thanks I want to take a moment to thank everyone who has contributed to my software career and supported me along the way. Your guidance, encouragement, and shared knowledge have been invaluable.\nIn alphabetical order:\nKaosSpectrum Middle Sharundaar Sov (SovereignDev) Travis Vroman YawLighthouse You’ve all inspired and helped me in ways that words alone can’t fully capture. Thank you for being part of this journey.\nP.S. If you’re curious about Lumina or any of my projects, feel free to explore, follow along, or reach out. Collaboration and discussion are always welcome!\n","date":"16 August, 2024","id":17,"permalink":"/about/aboutme/","summary":"Hello, and welcome to my blog!","tags":"","title":"About Me"},{"content":"Hello, I wanted to talk about some ways you can improve networking performance in C++ by understanding and implementing efficient network serialization in Unreal Engine. Effective serialization is critical for transmitting data across the network without unnecessary overhead, especially in multiplayer games where bandwidth is limited.\nThis article assumes basic familiarization with Unreal Engine\u0026rsquo;s networking system.\nWhat is Network Serialization? Serialization in the context of networking refers to the process of converting data into a format that can be easily transmitted over a network and reconstructed later. In Unreal Engine, this process is crucial for ensuring that game states, variables, and objects are accurately synchronized between clients and servers.\nUnreal Engine\u0026rsquo;s Built-in Serialization Unreal Engine provides built-in support for serialization with its powerful reflection system. This system can automatically serialize properties marked with specific macros, making it easy to sync variables across the network.\nHere’s an example of a simple struct that can be serialized, and forcing it to be atomic:\nUSTRUCT(BlueprintType) struct FPlayerData { GENERATED_BODY() UPROPERTY(EditAnywhere, BlueprintReadWrite, Category=\u0026#34;Player Data\u0026#34;) int32 Health; UPROPERTY(EditAnywhere, BlueprintReadWrite, Category=\u0026#34;Player Data\u0026#34;) int32 Armor; UPROPERTY(EditAnywhere, BlueprintReadWrite, Category=\u0026#34;Player Data\u0026#34;) FVector Location; // Serializes the data for network transmission friend FArchive\u0026amp; operator\u0026lt;\u0026lt;(FArchive\u0026amp; Ar, FPlayerData\u0026amp; Data) { Ar \u0026lt;\u0026lt; Data.Health; Ar \u0026lt;\u0026lt; Data.Armor; Ar \u0026lt;\u0026lt; Data.Location; return Ar; } }; In this example, the FPlayerData struct contains the player\u0026rsquo;s health, armor, and location. The operator\u0026lt;\u0026lt; overload is implemented to serialize these properties, ensuring that they can be packed into a network packet and sent over the network.\nA common point of confusion when first learning about any type of serialization in Unreal is the use of the \u0026lt;\u0026lt; operator. This operator works both during reading, and writing. FArchive has functions to determine which mode it\u0026rsquo;s in. Such as the write mode with Ar.IsSaving or the read mode with Ar.IsLoading. This enables you to control how things get serialized during both read and write operations.\nSomething important to node about overriding the \u0026lt;\u0026lt; operator, is that it\u0026rsquo;s used for ALL types of serialization, not just networking. Don\u0026rsquo;t worry, there are ways to specifically control serialization ONLY during network serialization.\nUnreal has a powerful Struct Trait System, now forewarning, the syntax may look a bit weird. But here is an example of how we can declare a UStruct with a Network Serializer\ntemplate\u0026lt;\u0026gt; struct TStructOpsTypeTraits\u0026lt;FPlayerData\u0026gt; : public TStructOpsTypeTraitsBase2\u0026lt;FPlayerData\u0026gt; { enum { WithNetSerializer = true, }; }; This TStructOpsTypeTraits lets you define very specific ways a structure gets used, looking inside of Class.h we can see all of the struct traits to cover custom aspects of UStructs\n/** type traits to cover the custom aspects of a script struct **/ template \u0026lt;class CPPSTRUCT\u0026gt; struct TStructOpsTypeTraitsBase2 { enum { WithZeroConstructor = false, // struct can be constructed as a valid object by filling its memory footprint with zeroes. WithNoInitConstructor = false, // struct has a constructor which takes an EForceInit parameter which will force the constructor to perform initialization, where the default constructor performs \u0026#39;uninitialization\u0026#39;. WithNoDestructor = false, // struct will not have its destructor called when it is destroyed. WithCopy = !TIsPODType\u0026lt;CPPSTRUCT\u0026gt;::Value, // struct can be copied via its copy assignment operator. WithIdenticalViaEquality = false, // struct can be compared via its operator==. This should be mutually exclusive with WithIdentical. WithIdentical = false, // struct can be compared via an Identical(const T* Other, uint32 PortFlags) function. This should be mutually exclusive with WithIdenticalViaEquality. WithExportTextItem = false, // struct has an ExportTextItem function used to serialize its state into a string. WithImportTextItem = false, // struct has an ImportTextItem function used to deserialize a string into an object of that class. WithAddStructReferencedObjects = false, // struct has an AddStructReferencedObjects function which allows it to add references to the garbage collector. WithSerializer = false, // struct has a Serialize function for serializing its state to an FArchive. WithStructuredSerializer = false, // struct has a Serialize function for serializing its state to an FStructuredArchive. WithPostSerialize = false, // struct has a PostSerialize function which is called after it is serialized WithNetSerializer = false, // struct has a NetSerialize function for serializing its state to an FArchive used for network replication. WithNetDeltaSerializer = false, // struct has a NetDeltaSerialize function for serializing differences in state from a previous NetSerialize operation. WithSerializeFromMismatchedTag = false, // struct has a SerializeFromMismatchedTag function for converting from other property tags. WithStructuredSerializeFromMismatchedTag = false, // struct has an FStructuredArchive-based SerializeFromMismatchedTag function for converting from other property tags. WithPostScriptConstruct = false, // struct has a PostScriptConstruct function which is called after it is constructed in blueprints WithNetSharedSerialization = false, // struct has a NetSerialize function that does not require the package map to serialize its state. WithGetPreloadDependencies = false, // struct has a GetPreloadDependencies function to return all objects that will be Preload()ed when the struct is serialized at load time. WithPureVirtual = false, // struct has PURE_VIRTUAL functions and cannot be constructed when CHECK_PUREVIRTUALS is true WithFindInnerPropertyInstance = false,\t// struct has a FindInnerPropertyInstance function that can provide an FProperty and data pointer when given a property FName WithCanEditChange\t= false,\t// struct has an editor-only CanEditChange function that can conditionally make child properties read-only in the details panel (same idea as UObject::CanEditChange) }; static constexpr EPropertyObjectReferenceType WithSerializerObjectReferences = EPropertyObjectReferenceType::Conservative; // struct\u0026#39;s Serialize method(s) may serialize object references of these types - default Conservative means unknown and object reference collector archives should serialize this struct }; To see a very good example of this system in use, we can look at FVector_NetQuantize, located inside of NetSerialization.h.\nUSTRUCT(meta = (HasNativeMake = \u0026#34;/Script/Engine.KismetMathLibrary.MakeVector_NetQuantize\u0026#34;, HasNativeBreak = \u0026#34;/Script/Engine.KismetMathLibrary.BreakVector_NetQuantize\u0026#34;)) struct FVector_NetQuantize : public FVector { GENERATED_USTRUCT_BODY() FORCEINLINE FVector_NetQuantize() {} explicit FORCEINLINE FVector_NetQuantize(EForceInit E) : FVector(E) {} FORCEINLINE FVector_NetQuantize(double InX, double InY, double InZ) : FVector(InX, InY, InZ) {} FORCEINLINE FVector_NetQuantize(const FVector \u0026amp;InVec) { FVector::operator=(InVec); } bool NetSerialize(FArchive\u0026amp; Ar, class UPackageMap* Map, bool\u0026amp; bOutSuccess) { bOutSuccess = SerializePackedVector\u0026lt;1, 20\u0026gt;(*this, Ar); return true; } }; template\u0026lt;\u0026gt; struct TStructOpsTypeTraits\u0026lt; FVector_NetQuantize \u0026gt; : public TStructOpsTypeTraitsBase2\u0026lt; FVector_NetQuantize \u0026gt; { enum { WithNetSerializer = true, WithNetSharedSerialization = true, }; }; Brushing over the boilerplate code, we can see that FVector_NetQuantize implements the trait WithNetSerializer = true, and then the function:\nbool NetSerialize(FArchive\u0026amp; Ar, class UPackageMap* Map, bool\u0026amp; bOutSuccess) -is implemented, this gives us full access to the FArchive responsible for the network serialization.\nAnother important trait is WithNetDeltaSerializer, which enables you direct access to determine what changes between two NetSerialize function calls, FFastArraySerializer takes advantage of this.\nOptimizing Serialization for Performance While Unreal Engine handles a lot of serialization automatically, there are ways to optimize it for better performance:\nMinimize Data Transmission: Only serialize and send the data that is absolutely necessary. Avoid transmitting redundant or static data that doesn\u0026rsquo;t change often.\nUse Compression: If you’re sending large amounts of data, consider compressing it before serialization. Unreal Engine provides built-in functions like FArchive for this purpose.\nCustom Serialization: For complex objects, implement custom serialization logic to control exactly how data is packed and unpacked, which can reduce the size of your network packets.\nExample: Custom Serialization with Compression Here’s a quick example of custom serialization with compression:\nvoid AMyPlayerState::SerializeCompressedData(FArchive\u0026amp; Ar) { if (Ar.IsSaving()) { TArray\u0026lt;uint8\u0026gt; UncompressedData; FMemoryWriter MemoryWriter(UncompressedData, true); MemoryWriter \u0026lt;\u0026lt; PlayerData; // Compress the data TArray\u0026lt;uint8\u0026gt; CompressedData; FCompression::CompressMemory(NAME_Zlib, CompressedData.GetData(), CompressedData.Max(), UncompressedData.GetData(), UncompressedData.Num()); // Serialize compressed data Ar \u0026lt;\u0026lt; CompressedData; } else if (Ar.IsLoading()) { TArray\u0026lt;uint8\u0026gt; CompressedData; Ar \u0026lt;\u0026lt; CompressedData; TArray\u0026lt;uint8\u0026gt; UncompressedData; FCompression::UncompressMemory(NAME_Zlib, UncompressedData.GetData(), UncompressedData.Max(), CompressedData.GetData(), CompressedData.Num()); FMemoryReader MemoryReader(UncompressedData, true); MemoryReader \u0026lt;\u0026lt; PlayerData; } } In this example, data is compressed using the Zlib algorithm before being serialized, reducing the amount of data transmitted over the network. When received, the data is uncompressed and deserialized back into the original format.\nLet\u0026rsquo;s say you have a very very large structure, but that structure might not always be full of every piece of information that can be packaged into it, do we still have to replicate all the properties in the struct even if they\u0026rsquo;re empty? NO.\nWe can take advantage of the NetSerialize and access to the FArchive responsible by implementing something called Bit Counting or Rep Bit Counting\nBit Counting is when you pack informatin into a bit uint8 uint32 (or whatever you suits your requirements) and determine what needs to get packaged up during the Ar.IsSaving phase. Let\u0026rsquo;s take a look at FGameplayEffectContext from the Gameplay Ability System\nbool FGameplayEffectContext::NetSerialize(FArchive\u0026amp; Ar, class UPackageMap* Map, bool\u0026amp; bOutSuccess) { uint8 RepBits = 0; if (Ar.IsSaving()) { if (bReplicateInstigator \u0026amp;\u0026amp; Instigator.IsValid()) { RepBits |= 1 \u0026lt;\u0026lt; 0; } if (bReplicateEffectCauser \u0026amp;\u0026amp; EffectCauser.IsValid() ) { RepBits |= 1 \u0026lt;\u0026lt; 1; } if (AbilityCDO.IsValid()) { RepBits |= 1 \u0026lt;\u0026lt; 2; } if (bReplicateSourceObject \u0026amp;\u0026amp; SourceObject.IsValid()) { RepBits |= 1 \u0026lt;\u0026lt; 3; } if (Actors.Num() \u0026gt; 0) { RepBits |= 1 \u0026lt;\u0026lt; 4; } if (HitResult.IsValid()) { RepBits |= 1 \u0026lt;\u0026lt; 5; } if (bHasWorldOrigin) { RepBits |= 1 \u0026lt;\u0026lt; 6; } } Ar.SerializeBits(\u0026amp;RepBits, 7); if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 0)) { Ar \u0026lt;\u0026lt; Instigator; } if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 1)) { Ar \u0026lt;\u0026lt; EffectCauser; } if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 2)) { Ar \u0026lt;\u0026lt; AbilityCDO; } if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 3)) { Ar \u0026lt;\u0026lt; SourceObject; } if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 4)) { SafeNetSerializeTArray_Default\u0026lt;31\u0026gt;(Ar, Actors); } if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 5)) { if (Ar.IsLoading()) { if (!HitResult.IsValid()) { HitResult = TSharedPtr\u0026lt;FHitResult\u0026gt;(new FHitResult()); } } HitResult-\u0026gt;NetSerialize(Ar, Map, bOutSuccess); } if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 6)) { Ar \u0026lt;\u0026lt; WorldOrigin; bHasWorldOrigin = true; } else { bHasWorldOrigin = false; } if (Ar.IsLoading()) { AddInstigator(Instigator.Get(), EffectCauser.Get()); // Just to initialize InstigatorAbilitySystemComponent }\tbOutSuccess = true; return true; } What in the world is this giant thing? Well it\u0026rsquo;s actually pretty simple, you see FGameplayEffectContext is a very large struct. size: 128, alignment: 8, and we might not always have every bit of information packed into every one of those variables. So we can take advantage of bit counting to determine what actually needs to get serialized up.\nuint8 RepBits = 0; if (Ar.IsSaving()) { if (bReplicateInstigator \u0026amp;\u0026amp; Instigator.IsValid()) { RepBits |= 1 \u0026lt;\u0026lt; 0; } if (bReplicateEffectCauser \u0026amp;\u0026amp; EffectCauser.IsValid() ) { RepBits |= 1 \u0026lt;\u0026lt; 1; } if (AbilityCDO.IsValid()) { RepBits |= 1 \u0026lt;\u0026lt; 2; } if (bReplicateSourceObject \u0026amp;\u0026amp; SourceObject.IsValid()) { RepBits |= 1 \u0026lt;\u0026lt; 3; } if (Actors.Num() \u0026gt; 0) { RepBits |= 1 \u0026lt;\u0026lt; 4; } if (HitResult.IsValid()) { RepBits |= 1 \u0026lt;\u0026lt; 5; } if (bHasWorldOrigin) { RepBits |= 1 \u0026lt;\u0026lt; 6; } } This part here, only happens when the FArchive is in the write mode, at that time, you determine which properties have relevant values, and simply mark a flag into the uint8 RepBits, stating that something exists at that point we may want later.\nThe next part happens for both writing and reading. At whichtime the RepBits is serialized to the number of entries we put into it, (in this case 7 bits), and then as we come through the struct, we look and see which properties are relevant, and if they are. We serialize them with the \u0026lt;\u0026lt; operator, or by calling the property\u0026rsquo;s custom NetSerialize function. When this gets read on the other side, the order is maintained through the RepBits, so the reader has the ability to unpack the structure in the correct order. Which is *Extremely important. Both reading and writing needs to happen in the same order, due to how buffers work. We use the uint8 to maintain a small way to send the data through the network which contains our information about what was actually read to the archiver.\nAr.SerializeBits(\u0026amp;RepBits, 7); if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 0)) { Ar \u0026lt;\u0026lt; Instigator; } if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 1)) { Ar \u0026lt;\u0026lt; EffectCauser; } if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 2)) { Ar \u0026lt;\u0026lt; AbilityCDO; } if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 3)) { Ar \u0026lt;\u0026lt; SourceObject; } if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 4)) { SafeNetSerializeTArray_Default\u0026lt;31\u0026gt;(Ar, Actors); } if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 5)) { if (Ar.IsLoading()) { if (!HitResult.IsValid()) { HitResult = TSharedPtr\u0026lt;FHitResult\u0026gt;(new FHitResult()); } } HitResult-\u0026gt;NetSerialize(Ar, Map, bOutSuccess); } if (RepBits \u0026amp; (1 \u0026lt;\u0026lt; 6)) { Ar \u0026lt;\u0026lt; WorldOrigin; bHasWorldOrigin = true; } else { bHasWorldOrigin = false; } if (Ar.IsLoading()) { AddInstigator(Instigator.Get(), EffectCauser.Get()); // Just to initialize InstigatorAbilitySystemComponent }\tbOutSuccess = true; return true; Conclusion Efficient network serialization is essential for any multiplayer game developed in Unreal Engine. By understanding and optimizing how data is serialized, you can significantly reduce network overhead, leading to smoother and more responsive gameplay.\nIf you’re looking to enhance your game’s networking performance, start by analyzing what data you’re sending across the network and consider implementing custom serialization strategies to optimize it.\nBy following these guidelines and examples, you\u0026rsquo;ll be well on your way to improving your Unreal Engine project\u0026rsquo;s networking performance. Happy coding!\n","date":"16 August, 2024","id":18,"permalink":"/posts/networking/networkserialization/","summary":"Hello, I wanted to talk about some ways you can improve networking performance in C++ by understanding and implementing efficient network serialization in Unreal Engine. Effective serialization is critical for transmitting data across the network without unnecessary overhead, especially in multiplayer games where bandwidth is limited.","tags":"UnrealEngine Networking","title":"Network Serialization"}]